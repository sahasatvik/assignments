\documentclass[11pt]{article}

\usepackage[T1]{fontenc}
\usepackage{geometry}
\usepackage{amsmath, amssymb, amsthm}
\usepackage[%
    hidealllines=true,%
    innerbottommargin=15,%
    nobreak=true,%
]{mdframed}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage[hidelinks]{hyperref}
\usepackage{fancyhdr}
\usepackage{lipsum}
\usepackage{bm}
\usepackage{braket}
\usepackage{siunitx}
\usepackage[scr=boondoxupr]{mathalpha}

\geometry{a4paper, margin=1in, headheight=14pt}

\pagestyle{fancy}
\fancyhf{}
\renewcommand\headrulewidth{0.4pt}
\fancyhead[L]{\scshape PH2201}
\fancyhead[R]{\scshape \leftmark}
\rfoot{\footnotesize\it Updated on \today}
\cfoot{\thepage}

\def\C{\mathbb{C}}
\def\R{\mathbb{R}}
\def\Q{\mathbb{Q}}
\def\Z{\mathbb{Z}}
\def\N{\mathbb{N}}
\newcommand\ve[1]{\boldsymbol{#1}}
\newcommand\ddx[1]{\frac{d #1}{d x}}
\newcommand\ddt[1]{\frac{d #1}{d t}}
\newcommand\dd[3][]{\frac{d^{#1}{#2}}{d {#3}^{#1}}}
\newcommand\ppx[1]{\frac{\partial #1}{\partial x}}
\newcommand\ppt[1]{\frac{\partial #1}{\partial t}}
\newcommand\pp[3][]{\frac{\partial^{#1}{#2}}{\partial {#3}^{#1}}}
\newcommand\norm[1]{\left\lVert#1\right\rVert}
\newcommand\grad[1]{\ve{\nabla}#1}
\newcommand\divg[1]{\ve{\nabla}\cdot#1}
\newcommand\curl[1]{\ve{\nabla}\times#1}
\newcommand\lapl[1]{\nabla^2 #1}
\newcommand\E[1]{\langle #1 \rangle}

\def\vr{\ve{r}}
\def\vp{\ve{p}}
\def\vv{\ve{v}}
\def\vk{\ve{k}}
\def\vL{\ve{L}}
\def\vJ{\ve{J}}
\def\vS{\ve{S}}
\def\ver{\ve{\hat{e}_r}}
\def\veth{\ve{\hat{e}_\theta}}
\def\veph{\ve{\hat{e}_\phi}}

\newmdtheoremenv[%
    backgroundcolor=blue!10!white,%
]{theorem}{Proposition}[section]
% \newmdtheoremenv[%
%     backgroundcolor=violet!10!white,%
% ]{corollary}{Corollary}[theorem]
% \newmdtheoremenv[%
%     backgroundcolor=teal!10!white,%
% ]{lemma}[theorem]{Lemma}

\theoremstyle{definition}
\newmdtheoremenv[%
    backgroundcolor=green!10!white,%
]{definition}{Definition}[section]
\newmdtheoremenv[%
    backgroundcolor=red!10!white,%
]{exercise}{Exercise}[section]
\newmdenv[%
    hidealllines=false,%
    linecolor=black!20!white,%,
    % backgroundcolor=cyan!5!white,%
    innertopmargin=10,%
]{equationbox}
\newenvironment{boxedeq}%
    {\begin{equationbox}\begin{equation}}%
    {\end{equation}\end{equationbox}}
\newenvironment{boxedeq*}%
    {\begin{equationbox}\begin{equation*}}%
    {\end{equation*}\end{equationbox}}

\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\newtheorem*{example}{Example}

\numberwithin{equation}{section}

\title{
    \Large\textsc{PH2201} \\
    % \vspace{10pt}
    \Huge \textbf{Basic Quantum Mechanics} \\
    \vspace{5pt}
    \Large{Spring 2021}
}
\author{
    \large Satvik Saha%
    % \thanks{Email: \tt ss19ms154@iiserkol.ac.in}
    \\\textsc{\small 19MS154}
}
\date{\normalsize
    \textit{Indian Institute of Science Education and Research, Kolkata, \\
    Mohanpur, West Bengal, 741246, India.} \\
    % \vspace{10pt}
    % \today
}

\begin{document}
    \maketitle
    \tableofcontents

    \section{Introduction}
    The quantum world differs from the classical world in many aspects, most of
    which we seldom encounter in our daily lives and are hence unintuitive.
    \begin{itemize}
        \item The physical world is not deterministic; uncertainty is
        intrinsic to the quantum world.
        This is sometimes illustrated by the Schr\"odinger's cat thought
        experiment.
        \item Both light and matter exhibit characteristics of waves as well
        as those of particles.
        However, a single object cannot exhibit both of these properties 
        simultaneously.
        \item Physical quantities may be quantized -- they may be
        constrained to have discrete values rather than vary continuously.
    \end{itemize}

    \section{Duality of light}
    \subsection{Blackbody radiation}
    A blackbody is an object which absorbs all radiation incident on it, and
    reflects none. It also emits radiation of all frequencies.

    Kirchoff's Law says that the rates of emission and absorption of radiation of a
    body in thermal equilibrium will be equal. By thermal equilibrium, we mean that
    the temperatures of the body and its surroundings are equal.

    \begin{theorem}[Stefan-Boltzmann Law]
        The power emitted by a blackbody is given by \[
            P \,=\, \sigma A T^4.
        \]
        Here, $\sigma \approx 
        \SI{5.67e-8}{\joule\second^{-1}\meter^{-2}\kelvin^{-4}}$ is called the
        Stefan-Boltzmann constant.
    \end{theorem}

    We may break down the total energy density $\rho \propto T^4$ in terms of the
    contributions from each frequency, so \[
        \rho = \int_0^\infty \rho(\nu) \:d\nu.
    \] 
    It turns out that $\rho(\nu)$ is non-monotonic. This cannot be explained by
    classical mechanics (Rayleigh-Jean's Law), which predicts that $\rho(\nu)$
    is unbounded with increasing frequency -- the famous ultraviolet catastrophe.

    \begin{theorem}[Wien's Law]
        The positions of the peaks in $\rho(\nu)$ are described by \[
            \lambda_{peak} \,=\, \frac{w}{T}.
        \]
        Here, $w \approx \SI{2.9e-3}{\milli\kelvin}$.  
    \end{theorem}
    Note that at $T \approx \SI{300}{\kelvin}$, the peak wavelength $\lambda_{peak}$
    is in the infrared range: this is why night vision googles are useful.
    
    Consider a collection of electromagnetic waves in a blackbody cavity, with
    temperature $T$. This can be seen as the superposition of normal modes.
    The classical approach to the blackbody problem is to suppose that the energy
    density at a particular frequency is given by \[
        \rho(\nu) = \E{E} n(\nu),
    \] where $n(\nu)$ is the number density of wave modes with frequency $\nu$, and
    $E$ is the average energy of the radiation.

    The classical law of equipartition of energy gives \[
        \E{E} = k_B T,
    \] where $k_B$ is the Boltzmann constant.

    The wavenumber of for modes within the cavity is given by \[
        \ve{k} = \frac{2\pi}{L}\ve{n},
    \] where $\ve{n} = (n_x, n_y, n_z)$ with integral components. Now, \[
        \nu = \frac{c}{\lambda} = \frac{c}{L}n.
    \] Treating $n$ as a continuous variable and using $dV = 4\pi n^:dn$, we write
    \[
        n(\nu)\:d\nu = \frac{8\pi}{c^3}\nu^2\:d\nu.
    \] This leads to the Rayleigh-Jean Law,
    \begin{boxedeq*}
        \rho(\nu)\:d\nu = \E{E} n(\nu) \:d\nu 
            = \frac{8\pi k_B T}{c^3}\nu^2\:d\nu.
    \end{boxedeq*}\\~\\

    Planck looked at the probability distribution for the energy, \[
        P(E) = \frac{1}{k_B T}e^{-E /k_B T}.
    \] This is the Boltzmann distribution. It can be shown that \[
        \E{E} = \frac{\int_0^\infty E P(E) \:dE}{\int_0^\infty P(E) \: dE} 
        = k_B T,
    \] which recovers the Rayleigh-Jean Law.

    Planck's idea was to restrict $E$ to discrete values; integral multiples of the
    frequency $\nu$. This leads to \[
        \E{E} = \frac{\sum E P(E)}{\sum P(E)} 
            = \frac{h\nu}{e^{h\nu /k_B T} - 1}.
    \] 
    This gives us the Planck distribution.

    \begin{theorem}[Planck's Law]
        The spectral energy density of radiation emitted by a blackbody in thermal
        equilibrium is described by the distribution \[
            \rho(\nu)\:d\nu 
                = \frac{8\pi h}{c^3} \frac{\nu^3}{e^{h\nu /k_B T} - 1} \:d\nu.
        \] 
        Here, $h \approx \SI{6.626e-34}{\joule\second}$ is called Planck's constant.
    \end{theorem}
    When $h\nu \ll 1$, we recover the Rayleigh-Jean limit. When $h\nu \gg 1$, we get
    the Wien limit.

    Now we calculate, \[
        \rho = \int_0^\infty \rho(\nu)\:d\nu = \frac{8\pi^5k_B^4}{15c^3h^3}T^4,
    \] which recovers the Stefan-Boltzmann Law with \[
        \sigma \,=\, \frac{2\pi^5k_B^4}{15c^2h^3}.
    \] 
    Also, the maxima of the Planck distribution recovers Wien's Law, with \[
        \nu_{max} \,\approx\, 2.8 \frac{k_B T}{h}.
    \] 

    \subsection{Photoelectric effect}
    This reveals the dual nature of light. Classical optics relies on the wave
    nature of light, thus explaining phenomena such as interference and diffraction.
    This culminates in Maxwell's equations, which predict the wave nature of light
    as the propagation of oscillating electric and magnetic fields.

    The photoelectric effect in the phenomenon in which light shining on a metal
    surface ejects electrons from it, thus producing a current. Suppose that the
    incident light has frequency $\nu$, intensity $I$ and this produces a current
    $i$. We can calculate the maximum kinetic energy of the emitted electrons
    $E_{max} = eV_0$ by adjusting an opposing potential $V$.

    It turns out that for a constant intensity $I$, the photocurrent saturates at
    the same value. However, different frequencies $\nu$ produces different stopping
    potentials $V_0$; the greater the frequency, the greater the magnitude of the
    stopping potential. This turns out to have a linear relationship, with
    \begin{boxedeq*}
        E_{max} \,=\, eV_0 \,=\, h(\nu - \nu_0) \,=\, h\nu - \phi.
    \end{boxedeq*}
    The slope $h$ is universal for all metals, while $\phi = h\nu_0$ varies
    between different metals.
    This shows that below a certain frequency $\nu_0$, we obtain no photocurrent,
    regardless of the intensity! This appears strange from a classical perspective,
    where the energy delivered by an electromagnetic wave is related to its
    intensity, not its frequency.

    Einstein proposed that light strikes the metal in bundles of energy, all
    integral multiples of $h\nu$. There is also a minimum binding energy which must
    be overcome to liberate electrons from the metal surface -- this cannot be paid
    in a continuous manner, since any partial energy given to an electron will be
    lost before the arrival of the next energy bundle. Thus, each energy bundle must
    carry a minimum energy $h\nu_0$ in order to liberate electrons and produce a
    photocurrent.

    This establishes a particle-like mature of light. Each energy bundle, or
    particle of light, is called a photon.

    \section{Duality of matter}
    \subsection{Matter waves}
    Louis de Broglie further hypothesised that matter also has a wave nature, with
    an associated wavelength of 
    \begin{boxedeq*}
        \lambda_{matter} \,=\, \frac{h}{p}.
    \end{boxedeq*}
    This has been demonstrated by Davisson and Germer, where a stream of electrons
    exhibits diffraction.
    
    This has some amazing implications. In the classical world, knowledge of a
    particle's position and momentum is enough to pinpoint its trajectory with
    arbitrary precision. However, the wavelike nature of matter would imply that we
    can no longer talk of a definite, localized position when we have knowledge of
    the particle's momentum! This uncertainty is inherent to quantum mechanics.

    Another consequence is the phenomenon of quantum tunnelling.

    \subsection{Double slit experiment with pellets}
    Consider Young's double slit experiment, this time with pellets sprayed from a
    gun at a wall with two slits. The other sides has a collector, which is
    moveable. Assume that the pellets do not break, and that they arrive in groups
    independent of the rate of firing. We want to find the probability that a pellet
    lands at a distance $x$ from the centre of the screen.

    Now, this just means that we have to count the number of pellets which reach the
    detector in a given time interval. Also, we expect that the probability
    distribution for two slits ought to be the sum of the distributions for the
    individual slits, obtained by closing one slit at a time. The distribution for a
    single slit looks something like a Gaussian, so their combination should also
    look like a broad Gaussian.

    Note that this says nothing about phenomena such as interference.

    \subsection{Double slit experiment with electrons}
    Instead of using pellets, we now use electrons. These can be fired by heating
    a tungsten wire inside a box with a pinhole. Suppose that the detector at the
    other side produces a `click' whenever an electron strikes it; all such clicks
    are identical and random. The electrons are also fired very slowly, so that
    there is only one electron passing through the slits and hitting the screen at a
    given time. This means that we hear distinct, separate clicks at random
    intervals, which means that an electron must have passed through one of the
    slits at random before impacting the screen.

    What we observe is that over a long time, the probability distribution of the
    electrons is in the form of an interference pattern, just like with light waves.
    The strange thing is that if each electron passes through one slit at a time,
    the other slit ought to be `closed' from its perspective, which means that we
    ought to have obtained the superposition of two Gaussians!
    
    An attempt to explain this might be that the electrons follow some complex
    pathways incorporating both slits. On the other hand, the probability observed
    at the centre is greater than the sum of the probabilities for the single slits,
    and there are regions of zero probability on the screen where the single slit
    probabilities would suggest finite values. This would imply that closing a slit
    somehow increases the probabilities in one region and decreases that in another.

    Thus, the electrons arrive at the screen as particles, but their distribution on
    the screen shows interference patterns just like those of a wave!

    This suggests that a simple sum of the probabilities $P_1$ and $P_2$ from each
    of the slits is not enough. Analogous to the double slit experiment with light,
    we must assign complex probability amplitudes $A_1$ and $A_2$, which we then add
    up. \[
        P_1 = |A_1|^2, \qquad P_2 = |A_2|^2, \qquad P_{12} = |A_1 + A_2|^2.
    \] 
    
    \subsubsection{Spying on the electrons}
    Suppose that we repeat this experiment, but this time we place a detector on the
    slits. Thus, we can be sure which slit a given electron passes through.
    One way to do this is to place a light source in between the slits and the
    screen. When an electron passes through a slit, it will scatter some light which
    we see as a flash in the neighbourhood of the slit.

    What happens is that the interference pattern disappears! The distribution now
    has two peaks, just like a classical particle would behave, i.e.\ we now have
    $P_1 + P_2$.  We do indeed observe a single flash corresponding to each click,
    so we can pinpoint which slit a given electron on the screen corresponds to.

    To see whether the light source is somehow disturbing the paths of the
    electrons, we make it dimmer and dimmer.  Note that this merely changes the
    number of photons hanging around the slits, not their energy (which is $\propto
    h\nu$), so we do not expect the brightness of the flashes to change.  Now, some
    clicks do not have a corresponding flash; some electrons are reaching the screen
    unnoticed by our detector at the slits. The interference pattern at the screen
    gradually reappears, in the form $P_{12}$!

    Now, the momentum imparted by the light photons obeys $p = h / \lambda$. By
    choosing a very large $\lambda$, we can have $p \to 0$, which ought to disturb
    the electrons to a lesser extent. When we do this, we still observe the
    classical pattern. However, when $\lambda$ exceeds the order of the slit
    separation, we lose the ability to resolve which slit the electron passed
    through, i.e.\ the flashes cannot be identified with the correct slit. At this
    point, we get back the interference pattern. \\

    Thus, there is no way to answer which slit each electron passed through while
    retaining the interference pattern!
    This is intrinsic to the quantum system, in the form of the Heisenberg
    uncertainty principle.

    \section{Bohr's atomic model}
    Recall Rutherford's experiment where he fired $\alpha$ particles at a gold
    foil, which established the existence of a very small region of positive charge
    in the centre of every atom (the nucleus), surrounded by negatively charged
    electrons. This raises the problem of the stability of the electron orbits -- an
    accelerating charge must radiate energy, that too over a wide range of
    frequencies. On the other hand, radiation emitted by an atom is always observed
    at discrete frequencies. For example, the wavelengths emitted by hydrogen are 
    given by the Rydberg constant.
    \begin{boxedeq*}
        \frac{1}{\lambda} = R\left(\frac{1}{m^2} - \frac{1}{n^2}\right).
    \end{boxedeq*}
    Bohr's idea was that the angular momenta of the electrons are quantized. We set
    \[
        L = pr = mvr = n\hbar.
    \] In a sense, an electron forms a standing wave in its orbit, with a
    circumference of $n\lambda$. By balancing the Coulomb and centripetal forces, we
    can write \[
        r = \frac{4\pi\epsilon_0 \hbar^2}{me^2}n^2 = a_0n^2.
    \] Here, $a_0 \approx \SI{5.29e-11}{\meter}$ is called the Bohr radius.
    As a result, \[
        E_n = \frac{1}{2}mv^2 - \frac{e^2}{4\pi\epsilon_0 r} 
            \approx -13.6 \frac{1}{n^2}\,\si{e\volt}.
    \] The energies emitted by electrons are now restricted to differences of these
    energy levels, so \[
        h\nu = E_m - E_n.
    \] 

    \section{Postulates of quantum mechanics}
    \begin{enumerate}
        \itemsep0
        \item Associated with each classical outcome of a quantum experiment is a
        probability amplitude, $\Psi$, which is not directly observable.
        \item The probability distribution is given by $P = |\Psi|^2$, which is
        observable. For any physically interpretable wavefunction $\Psi$, we demand
        that $|\Psi|^2$ is normalizable. Thus, \[
            \int |\Psi|^2 \:dV = 1.
        \] As a consequence, we require $\Psi \to 0$ as we move away from the
        origin. We also demand $\Psi$ be continuous, and $\Psi'$ be continuous
        almost everywhere.
        \item For a system with many classical outcomes, we write \[
            \Psi = \sum_{i = 1}^\infty \Psi_i.
        \] Thus, the probability distribution $P$ carries signatures of the
        probabilities $P_i = |\Psi_i|^2$. For example when we have $n = 2$ 
        outcomes, \[
            P = |\Psi_1 + \Psi_2|^2 = P_1 + P_2 + 2\sqrt{P_1P_2}\cos\delta.
        \] 
    \end{enumerate}

    \subsection{The Schr\"odinger Equation}
    \begin{theorem}
        The wavefunction $\Psi$ must obey the differential equation \[
            \left[-\frac{\hbar^2}{2m}\lapl{} + V(\ve{r}, t)\right]\Psi(\ve{r}, t) =
            i\hbar \ppt{}\Psi(\ve{r}, t).
        \] 
    \end{theorem}
    Consider the simpler case where $V(\ve{r})$ has no time dependence.
    To solve this equation, we often perform separation of variables, \[
        \Psi(\ve{r}, t) = \psi(\ve{r})\, T(t).
    \] As a result, we observe that \[
        -\frac{1}{\psi}\frac{\hbar^2}{2m}\lapl{\psi} + V = \frac{i\hbar}{T}\ddt{T} =
        \text{constant}.
    \] The time part is solved by $T(t) = e^{-i E t/ \hbar}$, where the constant is
    denoted as $E$.  Note that we have shown $\Psi(\ve{r}, t) = \psi(\ve{r}) e^{-iEt
    /\hbar}$, so \[
        |\Psi|^2 = \Psi^*\Psi = \psi^*\psi = |\psi^2|,
    \] The spatial part must now satisfy 
    \begin{boxedeq*}
        -\frac{\hbar^2}{2m} \lapl{\psi} + V\psi = E\psi.
    \end{boxedeq*}
    which is called the time independent Schr\"odinger equation.
    The Hamiltonian operator is defined as \[
        \hat{H} = -\frac{\hbar^2}{2m}\lapl{} + V,
    \] so the spatial part of the equation says $\hat{H}\psi = E\psi$.
    In other words, the wavefunction $\Psi$ here is an eigenfunction of the
    Hamiltonian. The full solution can be written as a linear superposition of all
    such eigenfunctions $\Psi_i$.
    For convenience, we deal with only one spatial dimension here on.

    \subsection{Observables and operators}
    \begin{definition}[Expectation value]
        The expectation value of any linear operator $\hat{A}$ is defined as \[
            \E{\hat{A}} = \int_{-\infty}^{+\infty} \psi^* \hat{A} \psi \:dx.
        \]
    \end{definition}
    \begin{example}
        For example, the position, momentum, and energy operators are given by \[
            \hat{x} = x, \qquad \hat{p}_x = -i\hbar \ppx{}, \qquad \hat{E} = i\hbar
            \ppt{}.
        \] 
        This covers all physically observable quantities, and are thus called
        observables. Note that these are all linear operators.
    \end{example}

    What happens if $\psi$ is an eigenstate of $\hat{A}$, with eigenvalue $\lambda$?
    Note that $\hat{A}\psi = \lambda\psi$, so \[
        \E{\hat{A}} = \int_{-\infty}^{+\infty} \lambda \psi^*\psi\:dx = \lambda.
    \]

    \begin{theorem}[Ehrenfest's Theorem]
        The expectation values obey classical laws. For instance, \[
            \ddt{}\E{p} = \E{-\ppx{}V}.
        \] 
    \end{theorem}
    \begin{proof}
        We start by calculating 
        \begin{align*}
            \hat{p}\hat{H} - \hat{H}\hat{p} &= \left(-i\hbar
            \ppx{}\right)\left(\frac{\hbar^2}{2m}\pp[2]{}{x} + V\right)
            - \left(\frac{\hbar^2}{2m}\pp[2]{}{x} + V\right)\left(-i\hbar
            \ppx{}\right) \\
                &= -\frac{i\hbar^3}{2m}\pp[3]{}{x} - i\hbar\ppx{}V +
                \frac{i\hbar^3}{2m}\pp[3]{}{x} + i\hbar V\ppx{} \\
                &= -i\hbar \ppx{}V + i\hbar V\ppx{} \\
                &= -i\hbar \ppx{V}.
        \end{align*}
        Now, \[
            \ddt{\E{p}} = \int \ppt{\psi^*}\hat{p}\psi\:dx + \int \psi^*
            \ppt{\hat{p}}\psi\:dx + \int \psi^*\hat{p}\ppt{\psi}\:dx.
        \] The central term is just $\E{\partial \hat{p} / \partial t}$, which is zero.
        From the Schr\"odinger equation, we can write \[
            \hat{H}\psi = i\hbar\ppt{\psi}, \qquad (\hat{H}\psi)^* = \psi^*\hat{H} =
            -i\hbar \ppt{\psi^*}.
        \] Thus, \[
            \ddt{\E{p}} = \frac{1}{i\hbar} \int \psi^*(\hat{p}\hat{H} -
            \hat{H}\hat{p}) \psi \:dx =  \E{-\ppx{V}}. \qedhere
        \] 
    \end{proof}

    \begin{definition}[Commutator]
        The commutator of two linear operators $\hat{A}$ and $\hat{B}$ is defined as
        \[
            [\hat{A}, \hat{B}] = \hat{A}\hat{B} - \hat{B}\hat{A}.
        \] 
    \end{definition}
    
    In a statistical distribution, the first, second, third and fourth moments deal
    with the mean, standard deviation, skew and kurtosis. Skew is a measure of
    symmetry, and kurtosis is a measure of peakedness.

    \subsection{The uncertainty principle}
    \begin{theorem}[Heisenberg's Uncertainty Principle]
        The standard deviations of the position and momentum are related as \[
            \sigma_x \sigma_p \geq \frac{\hbar}{2}.
        \] More generally, for any two Hermitian operators, \[
            \sigma_A \sigma_B \geq \frac{1}{2}|\E{[\hat{A}, \hat{B}]}|.
        \] 
    \end{theorem}
    \begin{proof}
        We evaluate the following expression using integration by parts. \[
            i\hbar \int \ddx{\psi^*}\psi x\:dx = -i\hbar\int \psi^*\psi\:dx - i\hbar
            \int \ddx{\psi}\psi^* x\:dx = -i\hbar + \left[i\hbar \int \ddx{\psi^*}
            \psi x\:dx\right]^*
        \]
         Thus, \[
            2i\operatorname{Im}\int i\hbar \ddx{\psi^*}\psi x\:dx = -i\hbar. 
        \] Since $z^*z \geq b^2$, where $z = a + ib$, we must have \[
            4\left[\int i\hbar \ddx{\psi^*}\psi x\:dx\right]^2 \geq \hbar^2.
        \] Cauchy Schwarz gives \[
            \int x\psi^*\:x\psi \:dx \;\int
            \left(i\hbar\ppx{\psi^*}\right)\left(-i\hbar\ppx{\psi}\right) \:dx \geq
            \left[\int i\hbar \ddx{\psi^*}\psi x\:dx\right]^2 \geq
            \frac{\hbar^2}{4}.
        \] In other words, \[
            \E{x^2}\E{p^2} \geq \frac{\hbar^2}{4}.
        \] By writing $\sigma_x^2 = \E{x^2} - \E{x}^2$ and $\sigma_p^2 = \E{p^2} -
        \E{p}^2$, and by choosing $\E{x} = \E{p} = 0$, we arrive at the Heisenberg
        uncertainty principle, \[
            \sigma_x\sigma_p \geq \frac{\hbar}{2}. \qedhere
        \]
    \end{proof}

    Another uncertainty relation is the energy-time uncertainty, \[
        \sigma_E \sigma_t \geq \frac{\hbar}{2}.
    \]

    \subsection{Eigenstates and eigenvalues}
    Recall that the time independent Schr\"odinger equation is given by $\hat{H}\psi
    = E\psi$, which means that we seek eigenfunctions (or eigenstates) $\psi_n$ of
    the Hamiltonian, and their associated eigenvalues $E_n$. The eigenvalue $E_n$
    captures the time evolution of the associated eigenstate, since $\Psi_n = \psi_n
    e^{-iE_n t/ \hbar}$.

    \begin{definition}[Degenerate eigenstates]
        If two eigenstates $\psi_1$ and $\psi_2$ have the same energy eigenvalue,
        they are said to be degenerate with respect to one another.
    \end{definition}

    \begin{theorem}
        The energy eigenvalues of the Hamiltonian are real.
    \end{theorem}
    \begin{proof}
        This follows from the fact that the Hamiltonian is Hermitian, i.e.\
        $\hat{H}^* = \hat{H}$. Thus, if $E$ is an eigenvalue of $\hat{H}$ with
        the eigenstate $\psi$, then \[
            \hat{H}\psi = E\psi, \qquad \E{\hat{H}} = \int \psi^*\hat{H}\psi\:dx =
            E.
        \] Now, \[
            E^* = \int (\psi^*\hat{H}\psi)^*\:dx = \int \psi^*\hat{H}^*\psi\:dx = E,
        \] which forces $E \in \R$.
    \end{proof}

    \begin{theorem}
        Non-degenerate eigenstates of the Hamiltonian are orthonormal.
    \end{theorem}
    \begin{proof}
        Suppose that $\psi_1$ and $\psi_2$ are two non-degenerate eigenstates, with
        distinct eigenvalues $E_1$ and $E_2$. Then, \[
            \hat{H}\psi_1 = E_1\psi_1, \qquad \hat{H}\psi_2 = E_2\psi_2.
        \] Observe that \[
            \int \psi_1^*\hat{H}\psi_2\:dx = \int (\hat{H}^*\psi_1)^*\psi_2\:dx.
        \] Since the energy eigenvalues are real, we conclude that \[
            E_2 \int \psi_1^*\psi_2\:dx = E_1 \int \psi_1^*\psi_2\:dx.
        \] Since $E_1 \neq E_2$, the inner product must be zero.
    \end{proof}
    \begin{remark}
        If $\{\psi_i\}$ are degenerate, note that all linear combinations also form
        degenerate eigenstates. \[
            \hat{H}\sum c_i\psi_i = E\sum c_i\psi_i.
        \] Thus, although $\{\psi_i\}$ may not be orthonormal, we can apply the
        Gram-Schmidt process to obtain an orthonormal basis of that eigenspace.
    \end{remark}

    \begin{theorem}
        If $[\hat{A}, \hat{B}] = 0$, then $\hat{A}$ and $\hat{B}$ share
        non-degenerate eigenstates.
    \end{theorem}
    \begin{proof}
        Let $\psi$ be a non-degenerate eigenstate of $\hat{A}$, so $\hat{A}\psi =
        \lambda \psi$. Since $\hat{A}$ and $\hat{B}$ commute, \[
            \lambda \hat{B}\psi = \hat{B}\hat{A}\psi = \hat{A}\hat{B}\psi,
        \] so $\hat{B}\psi$ is also an eigenstate of $\hat{A}$ with eigenvalue
        $\lambda$. From the non-degeneracy of $\psi$, we must have $\hat{B}\psi =
        \mu\psi$ for some non-zero scalar $\mu$.
    \end{proof}
    
    \begin{theorem}
        The eigenstates of the time independent Schr\"odinger equation form a
        complete set of states, i.e.\ they form a basis of the set of all
        solutions. \[
            \Psi(x, t) = \sum c_n \psi_n(x) e^{-i E_n t/\hbar}.
        \] In order to obtain the coefficients $c_n$, we simply take inner products
        \[
            \int \Psi_n^*\Psi\:dx = c_n.
        \] 
    \end{theorem}
    \begin{proof}
        The first statement can be regarded as a postulate. The second follows from
        the orthonormality of the eigenstates, \[
            \int \psi_n^*\psi_m\:dx = \delta_{nm}.
        \] This means that with $\Psi_n = \psi_n e^{-iE_n t / \hbar}$, we have \[
            \int \psi_n^* \left[\sum c_m\psi_m e^{-i E_m t /\hbar}\right]e^{i E_n t
            / \hbar}\:dx = 
            \sum c_me^{-i (E_m - E_n) t / \hbar}\int \psi_n^*\psi_m\:dx = c_n.
            \qedhere
        \] 
    \end{proof}


    \section{Bound state problems}
    Here, we wish to solve the Schr\"dinger equation in one dimension with a time
    independent potential $V(x)$.

    \subsection{Piecewise constant potentials}
    If $V(x)$ is a constant over some interval, then we can write \[
        -\frac{\hbar^2}{2m}\dd[2]{\psi}{x} + (V - E)\psi = 0.
    \] Plugging in the Ansatz $\psi(x) = Ae^{kx}$, we obtain \[
        k = \pm\sqrt{\frac{2m}{\hbar^2}(V - E)}.
    \] Thus, our solution looks like \[
        \psi(x) = Ae^{kx} + Be^{-kx}, \qquad 
        \psi(x) = C\cos{\bar{k}x} + D\sin{\bar{k}x}
    \] depending on whether $V > E$ or $V < E$.
    We can stitch together these solutions over all such intervals by demanding the
    continuity of $\psi$ and $d\psi /dx$.

    \subsection{Infinite square well (particle in a box)}
    Consider a potential of the form \[
        V(x) = \begin{cases}
            0, &\text{ if }0 < x < a \\
            \infty &\text{ otherwise }
        \end{cases}
    \] Note that this forces $\psi(x) = 0$ outside the well where the potential is
    infinite. Now, setting $k = \sqrt{2mE} / \hbar$, we have the solution inside the
    well given by \[
        \psi(x) = A\cos{kx} + B\sin{kx}.
    \] We further demand $\psi(0) = \psi(a) = 0$, which forces $A = 0$ and $k = n\pi
    /a$ for integral values of $n$. Thus, we have 
    \begin{boxedeq*}
        \psi_n(x) = \sqrt{\frac{2}{a}}\sin{\frac{n\pi x}{a}}, \qquad
        E_n = \frac{n^2\pi^2\hbar^2}{2ma^2}.
    \end{boxedeq*}
    The factor of $\sqrt{2 / a}$ is required to normalize $\psi_n$.

    \subsection{Quantum harmonic oscillator}
    For any smooth potential $V(x)$ with a local minima at $x_0$, we can expand
    this as a Taylor series to write \[
        V(x) = V(x_0) + V'(x_0)(x - x_0) + \frac{1}{2}V''(x_0)(x - x_0)^2 + O(x^3).
    \] Noting that $V'(x_0) = 0$ and setting $V''(x_0) = m\omega^2$, we have \[
        V(x) \approx \frac{1}{2}m\omega^2x^2,
    \] which is the potential of a simple harmonic oscillator. This means that if 
    we want to solve the Schr\"odinger equation about a local minimum $x_0$ of the
    potential $V(x)$, we can solve
    \begin{boxedeq*}
        -\frac{\hbar^2}{2m}\dd[2]{\psi}{x} + \frac{1}{2}m\omega^2x^2\psi = E\psi.
    \end{boxedeq*}

    \subsubsection{Algebraic method}
    Rewrite the equation as follows. \[
        \frac{1}{2m}(p^2 + (m\omega x)^2) \psi = E\psi.
    \] This can be `factorized' in the following way. \[
        p^2 + (m\omega x)^2 = (ip + m\omega x)(-ip + m\omega x) + im[x, p].
    \] Note that $[x, p] = i\hbar$.
    We thus define the raising and lowering operators $a_+$ and $a_-$ as follows. \[
        a_\pm = \frac{1}{\sqrt{2m\omega\hbar}}(\mp ip + m\omega x).
    \] Their commutator can be calculated as \[
        [a_+, a_-] = \frac{1}{2m\omega\hbar}((-ip + m\omega x)(ip + m\omega x) -
        (ip + m\omega x)(-ip + m\omega x)) = -1.
    \] Note that $a_+$ and $a_-$ are not Hermitian, instead $a_+^* = a_-$.
    Now, \[
        a_- a_+ = \frac{1}{\hbar\omega}\hat{H} + \frac{1}{2}, \qquad
        \hat{H} = \hbar\omega\left(a_-a_+ - \frac{1}{2}\right) =
        \hbar\omega\left(a_+a_- + \frac{1}{2}\right).
    \]

    \begin{theorem}
        If $\psi$ is an eigenstate of the Hamiltonian, with eigenvalue $E$, then
        $a_+\psi$ is also an eigenstate with eigenvalue $E + \hbar\omega$, and $a_-\psi$
        is an eigenstate with eigenvalue $E - \hbar\omega$.
    \end{theorem}
    \begin{proof}
        If $\hat{H}\psi = E\psi$, then
        \begin{align*}
            \hat{H}(a_+\psi) &= \hbar\omega\left(a_+a_- + \frac{1}{2}\right)a_+\psi \\
            &= \hbar\omega \left(a_+a_-a_+ + \frac{1}{2}a_+\right)\psi \\
            &= \hbar\omega a_+ \left(a_-a_+ + \frac{1}{2}\right) \psi \\
            &= \hbar\omega a_+ \left(a_-a_+ - \frac{1}{2} + 1\right) \psi \\
            &= a_+ (\hat{H} + \hbar \omega) \psi \\
            &= (E + \hbar\omega)(a_+\psi).
        \end{align*}
        An analogous process shows that $\hat{H}(a_-\psi) = (E -
        \hbar\omega)(a_-\psi)$.
    \end{proof}

    For the existence of a ground state, we demand $a_-\psi_0 = 0$. This is because
    we want $\psi_0$ to be the state with the lowest possible energy, with no other
    states below it. Thus, the lowering operator must cause $\psi_0$ to vanish. It
    can be shown that \[
        \psi_0(x) = A_0e^{-m\omega x^2 / 2\hbar}.
    \] Plugging this into the Schr\"odinger equation, we see that this state has the
    energy eigenvalue \[
        E_0 = \frac{1}{2}\hbar\omega,
    \] which must be the lowest possible energy for the system. Thus, we get a set
    of solutions by repeatedly applying the raising operator.
    \begin{boxedeq*}
        \psi_n(x) = A_n(a_+)^n e^{-m\omega x^2 / 2\hbar}, \qquad
        E_n = \left(n + \frac{1}{2}\right) \hbar\omega.
    \end{boxedeq*}
    % It can be shown that \[
    %     A_n = \left(\frac{m\omega}{\pi\hbar}\right)^{1 / 4} 
    %     \frac{(-i)^n}{\sqrt{n!(\hbar\omega)^n}}.
    % \] \\ 
    To compute the normalisation coefficients, suppose that \[
        a_+ \psi_n = c_n \psi_{n + 1}, \qquad a_-\psi_n = d_n\psi_{n - 1}.
    \] Now, \[
        \int (a_+\psi_n)^*(a_+\psi_n)\:dx = \int \psi_n^* (a_-a_+)\psi_n\:dx = \int
        \psi_n^*\left(\frac{1}{\hbar\omega} \hat{H} + \frac{1}{2}\right)\psi_n\:dx.
    \] Due to normalisation, the first term is $|c_n|^2$. Expanding the final term,
    we have \[
        |c_n|^2 = \frac{1}{\hbar\omega}\int\psi_n^*\hat{H}\psi_n\:dx +
        \frac{1}{2}\int \psi_n^*\psi_n\:dx = \frac{1}{\hbar\omega}E_n + \frac{1}{2}
        = n + 1.
    \] Thus, we can choose $c_n = \sqrt{n + 1}$. Similarly, we can show that $d_n =
    \sqrt{n}$. This means that \[
        A_n = \frac{1}{\sqrt{n!}}A_0.
    \] We can also show that $\psi_i$ are orthogonal. \[
        \int \psi_m^*\psi_n\:dx = \delta_{mn}.
    \] 

    \subsubsection{Analytic method}
    We obtain a power series solution. Set $\xi = \sqrt{m\omega / \hbar} x$, $K = 2E
    / \hbar\omega$. The Schr\"odinger equation now reads \[
        \dd[2]{\psi}{\xi} = (\xi^2 - K)\psi.
    \] Note that when $\xi \gg K$, our equation has the approximate solution \[
        \psi(\xi) = Ae^{-\xi^2 / 2}.
    \] We drop the $e^{+\xi^2 / 2}$ term to ensure $\psi \to 0$ as $\xi \to \infty$.
    Now, we use the Ansatz \[
        \psi(\xi) = f(\xi)\, e^{-\xi^2 / 2},
    \] which when plugged into the differential equation demands \[
        f'' - 2\xi f' + (K - 1)f = 0.
    \] Writing $f$ as a power series, \[
        f(\xi) = \sum_{n = 0}^\infty a_n \xi^n, \quad 
        f'(\xi) = \sum_{n = 0}^\infty n a_n \xi^{n - 1}, \quad
        f''(\xi) = \sum_{n = 0}^\infty (n + 1)(n + 2)a_{n + 2}\xi^n.
    \] Thus, \[
        \sum_{n = 0}^\infty \left[(n + 1)(n + 2)a_{n + 2} - 2na_n + (K -
        1)a_n\right]\xi^n = 0,
    \] whence we obtain the recurrence relation \[
        a_{n + 2} = \frac{2n + 1 - K}{(n + 1)(n + 2)}a_n.
    \] Note that this gives two chains of even and odd coefficients, completely
    determined once we fix $a_0$ and $a_1$. When $n \gg K$, we have the
    approximation \[
        a_{n + 2} \approx \frac{2}{n}a_n, \qquad a_n \approx \frac{C}{(n / 2)!}.
    \] This means that $f(\xi)$ grows roughly as \[
        \sum \frac{C}{(n / 2)!}\xi^n = \sum \frac{C}{n!}\xi^{2n} = Ce^{\xi^2}.
    \] This would cause $\psi$ to diverge at infinity. To fix this, we demand that
    $a_{m + 2} = 0$ for some $m \in \N$ and also kill the other chain, which would
    force the power series to terminate. Thus, $2m + 1 = K$, so \[
        a_{n + 2} = \frac{2(n - m)}{(n + 1)(n + 2)}a_n, \qquad E_m = \left(m +
        \frac{1}{2}\right)\hbar\omega.
    \] This gives us our solutions $\psi_m$. For $\psi_0$, set $a_1 = 0$, which
    gives \[
        \psi_0(\xi) = a_0 e^{-\xi^2 / 2}, \qquad E_0 = \frac{1}{2}\hbar\omega.
    \] For $\psi_1$, set $a_1 = 0$, which gives \[
        \psi_1(\xi) = a_1\xi e^{-\xi^2 / 2}, \qquad E_0 = \frac{3}{2}\hbar\omega.
    \] In this manner, we can obtain all $\psi_m$ by using our recurrence relation.
    \begin{boxedeq*}
        \psi_n(\xi) = \left(\frac{m\omega}{\pi\hbar}\right)^{1 /4}
        \frac{1}{\sqrt{2^n n!}} H_n(\xi)\, e^{-\xi^2 / 2}, \qquad E_n = \left(n +
        \frac{1}{2}\right) \hbar\omega.
    \end{boxedeq*}
    Here, $H_n(\xi)$ are the Hermite polynomials.

    \section{Free particles}
    Consider a free particle, which entails $V(x) = 0$. Now, \[
        -\frac{\hbar^2}{2m}\dd[2]{\psi}{x} = E \psi, \qquad 
        \psi'' = -k^2\psi
    \] where $k^2 = 2mE / \hbar$. This gives the solutions \[
        \Psi(x, t) = Ae^{ik(x - \hbar kt / 2m)} + Be^{-ik(x + \hbar kt / 2m)}.
    \] This looks like the superposition of two waves moving left and right with
    speeds $v = \hbar k / 2m - \sqrt{E / 2m}$, and momenta $p = \hbar k$.
    This is not normalizable. To do this, we take the superposition of many such
    waves with different velocities, thus localizing the resultant `wave packet'.
    This gives \[
        \Psi(x, t) = \frac{1}{\sqrt{2\pi}} \int \phi(k)\, e^{ix(x - vt)}\:dk,
    \] for appropriate choice of $\phi(k)$. Initially, at $t = 0$, note that \[
        \psi(x, 0) = \frac{1}{\sqrt{2\pi}} \int \phi(k)\, e^{ikx}\:dk.
    \] The inverse Fourier transform directly gives $\phi$ as \[
        \phi(k) = \frac{1}{\sqrt{2\pi}} \int \psi(x, 0)\, e^{-ikx}\:dx.
    \] The phase velocity of a wave packet is defined as $v_p =\omega /k$, while the
    group velocity is $v_g = d\omega / dk$. We see that \[
        v_g = \frac{\hbar k}{m} = 2v_p.
    \] This resolves a discrepancy with the classical wave velocity and energy of
    $\sqrt{2E / m}$.

    \section{Scattering problems and quantum tunnelling}
    \subsection{Step function potential}
    Consider a potential of the form \[
        V(x) = V_0\, u(x) = \begin{cases}
            0, &\text{ if }x < 0 \\
            V_0, &\text{ if } x \geq 0
        \end{cases}
    \] Classically, we expect that a particle of energy $E$ moving from left to
    right will bounce back when $E < V_0$ and pass when $E > V_0$. 

    We have already solved the Schr\"odinger equation for constant potentials. The
    boundary conditions at $x = 0$ demand \[
        \psi(x \to 0^-) = \psi(x \to 0^+), \qquad
        \psi'(x \to 0^-) = \psi'(x \to 0^+).
    \] When $E > V_0$, the solutions are those of a free particle everywhere, with
    \[
        \psi(x) = \begin{cases}
            Ae^{ik_1x} + Be^{-ik_1x}, & x < 0, \quad k_1 = \sqrt{2mE / \hbar^2}, \\
            Ce^{ik_2x} + De^{-ik_2x}, & x \geq 0, \quad k_2 = \sqrt{2m(E - V_0) /
            \hbar^2}.
        \end{cases}
    \] We choose $D = 0$ on physical grounds, since we have a free particle coming
    in from the left. The boundary conditions give $A + B = C$ and $k_1(A - B) =
    k_2C$. With the choice $A = 1$, \[
        B = \frac{k_1 - k_2}{k_1 + k_2}, \qquad C = \frac{2k_1}{k_1 + k_2}.
    \] We call these the reflection and transmission amplitudes, which are the
    probability amplitudes for the reflection and transmission of the particle at
    the boundary. Note the analogy with Fresnel coefficients in optics.
    The reflection and transmission coefficients $R$ and $T$ can be set to $B^2$ and
    $C^2$. See that \[
        R + \frac{k_2}{k_1}T = 1.
    \] When $E < V_0$, we have \[
        \psi(x) = \begin{cases}
            Ae^{ik_1x} + Be^{-ik_1x}, & x < 0, \quad k_1 = \sqrt{2mE / \hbar^2}, \\
            Ce^{k_2x} + De^{-k_2x}, & x \geq 0, \quad k_2 = \sqrt{2m(V_0 - E) /
            \hbar^2}.
        \end{cases}
    \] This time, we set $C = 0$ and $A = 1$. The boundary conditions $1 + B = D$
    and $ik_1(1 - B) = -k_2D$ give \[
        B = \frac{k_1 - ik_2}{k_1 + ik_2}, \qquad D = \frac{2k_1}{k_1 + ik_2}.
    \] With $R = |B|^2$, we now have \[
        R = 1, \qquad T = \frac{k_1}{k_2}(1 - R) = 0.
    \] Thus, even though $T = 0$, we still have $\psi(x) \neq 0$ for $x \geq 0$!
    This phenomenon is called \textit{quantum tunnelling}.
    There is an analogy here with evanescent waves during total internal reflection.

    \subsection{Finite potential barrier}
    Consider a potential of the form \[
        V(x) = \begin{cases}
            0, &\text{ if }x < 0 \\
            V_0, &\text{ if } 0 \leq x \leq a \\
            0, &\text{ if } a < x
        \end{cases}
    \] We solve this as \[
        \psi(x) = \begin{cases}
            e^{ik_1x} + re^{-ik_1x}, & x < 0, \quad\qquad\! k_1 = \sqrt{2mE /
            \hbar^2}, \\
            Ae^{ik_2x} + Be^{-ik_2x}, & 0 \leq x \leq a, \quad k_2 = \sqrt{2m(E -
            V_0) / \hbar^2}, \\
            te^{ik_1x}, & a < x.
        \end{cases}
    \] Applying our boundary conditions, \[
        1 + r = A + B, \qquad k_1(1 - r) = k_2(A - B),
    \] \[
        te^{ik_1a} = Ae^{ik_2a} + Be^{-ik_2a}, \qquad 
        k_1te^{ik_1a} = k_2(Ae^{ik_2a} - Be^{-ik_2a}). \quad
    \] Set $\mu = k_2 /k_1 = \sqrt{1 - V_0 /E}$, and $\mathscr{A} = (1 +
    \mu^2)\sin{k_2a} + 2\mu i\cos{k_2 a}$. We can show that \[
        r = (1 - \mu^2)\sin{k_2a} / \mathscr{A}, \qquad 
        t = 2\mu ie^{-ik_1a} / \mathscr{A}, \qquad\quad
    \] \[
        A = i(1 + \mu)e^{-ik_2a} / \mathscr{A}, \qquad 
        B = -i(1 - \mu)e^{ik_2a} / \mathscr{A}.
    \] When $E > 0$ and $E \geq V_0$, the transmission coefficient $T = |t|^2$ is
    given by \[
        T = \frac{4\mu^2}{(1 + \mu^2)^2\sin^2{k_2a} + 4\mu^2\cos^2{k_2a}} = 
        \frac{1}{1 + \frac{1}{4}\left(\frac{1 - \mu^2}{\mu}\right)^2 \sin^2{k_2a}}.
    \] Note that $T \leq 1$, and $R = 1 - T$. Whenever $k_2a = n\pi$, the system is
    in resonance and we get perfect transmission. Also, \[
        E_n = V_0 + \frac{n^2\pi^2\hbar^2}{2ma^2}.
    \] Note the similarities with the `particle in a box' system, and a Fabry-Perot
    interferometer cavity. Thus, we have standing waves formed in the region $[0,
    a]$ at such resonance energies.

    On the other hand, in the limit $E \to V_0^+$ and for very small $a$, we have \[
        T \approx 1 - \frac{mV_0a^2}{2\hbar^2}.
    \] 

    When $E < V_0$, the quantity $k_2$ is imaginary, say $k_2 = iK$. With $\mu' =
    k_1 / K$, \[
        T = \frac{4\mu'^2}{(1 - \mu'^2)\sinh^2{Ka} + 4\mu'^2\cosh^2{Ka}}.
    \] As $E \to 0^+$, we have $T \to 0$ and $R \to 1$. This is another case of
    quantum tunnelling.
    
    \section{The Schr\"odinger equation in 3D}
    \subsection{Particle in a 3D box}
    Consider a potential of the form \[
        V(\ve{r}) = \begin{cases}
            0, &\text{ if } 0 < x < a,\; 0 < y < b,\; 0 < z < c \\
            \infty, &\text{ otherwise }
        \end{cases}
    \] We perform separation of variables \[
        \psi(\ve{r}) = \psi_x(x)\,\psi_y(y)\,\psi_z(z),
    \] and plug this into the time independent Schr\"odinger equation inside the box
    \[
        -\frac{\hbar^2}{2m}\lapl{\psi} = E\psi.
    \] This gives \[
        \sum \frac{1}{\psi_i}\pp[2]{\psi_i}{x_i} = -\frac{2mE}{\hbar^2}.
    \] We can thus write \[
        \frac{1}{\psi_x}\pp[2]{\psi_x}{x} = -\frac{2mE_x}{\hbar^2}, \qquad
        \frac{1}{\psi_y}\pp[2]{\psi_y}{y} = -\frac{2mE_y}{\hbar^2}, \qquad
        \frac{1}{\psi_z}\pp[2]{\psi_z}{z} = -\frac{2mE_z}{\hbar^2}.
    \] We know how to solve these equations; these just give the one dimensional
    `particle in a box' solutions. Thus, 
    \begin{boxedeq*}
        \psi(\ve{r}) = A \sin\frac{n_x\pi x}{a}\sin\frac{n_y\pi
        x}{b}\sin\frac{n_z\pi x}{c}, \qquad 
        E = \frac{\hbar^2\pi^2}{2m}\left(\frac{n_x^2}{a^2} + \frac{n_y^2}{b^2} +
        \frac{n_z^2}{c^2}\right).
    \end{boxedeq*}
    Note that the ground state corresponds to $n_x = n_y = n_z = 1$.
    
    \subsection{Angular momentum}
    We write \[
        \vL = \vr \times \vp = L_x\hat{i} + L_y\hat{j} + L_z\hat{k}, \qquad
        L_i = x_jp_k - x_kp_j.
    \] It can be shown that $\vL$ is Hermitian. Furthermore, the commutators are of
    the form \[
        [L_x, L_y] = i\hbar L_z, \qquad 
        [L_y, L_z] = i\hbar L_x, \qquad 
        [L_z, L_x] = i\hbar L_y.
    \] This immediately gives us uncertainty relations between the different
    components of the angular momentum. In other words, simultaneous eigenstates of
    any pair of $L_x, L_y, L_z$ do not exist. However, note that \[
        [L^2, L_i] = 0, \qquad
        L^2 = L_x^2 + L_y^2 + L_z^2.
    \] Thus, we can get simultaneous eigenfunctions of $L^2$ and any one component,
    say $L_z$.

    The total angular momentum $\vJ$ of an atomic system is given as the sum of 
    the orbital and spin angular momenta. \[
        \vJ = \vL + \vS.
    \] We get back the commutation relations exactly the same as for $\vL$.
    Now, we define the ladder operators \[
        J_+ = J_x + iJ_y, \qquad J_- = J_x - iJ_y, \qquad 
        [J_x, J_y] = 2\hbar J_z.
    \] Again, $J_+^* = J_-$, which means that the ladder operators are not Hermitian.
    Now, let $\psi$ be a simultaneous eigenstate of $J^2$ and $J_z$, with $J^2\psi =
    \alpha\psi$ and $J_z\psi = \beta\psi$. Setting $\varphi = J_+\psi$, we have \[
        J^2\varphi = \alpha\varphi.
    \] Thus, $J_+$ does not change the eigenvalues of eigenstates of $J^2$. However,
    note that the commutator $[J_z, J_+]$ is non-zero, with \[
        [J_z, J_+] = i\hbar J_y + \hbar J_x = \hbar J_+.
    \] Similarly, \[
        [J_z, J_-] = \hbar J_-.
    \] Thus, we calculate \[
        J_z\varphi = J_z J_+\psi = (\beta + \hbar)\varphi.
    \] This shows that the raising operator gives another eigenstate with eigenvalue
    incremented by $\hbar$. Similarly, \[
        J_zJ_-\psi = (\beta - \hbar)(J_-\psi),
    \] so the lowering operator lowers the eigenvalue by $\hbar$.
    On the other hand, this cannot proceed indefinitely, since the eigenvalues must
    be bounded as $\beta^2 \leq \alpha$, since $J_z^2 \leq J^2$. This means that we
    have two states, \[
        J_+\psi_{max} = 0, \qquad J_-\psi_{min} = 0.
    \] Write \[
        J^2 = J_-J_+ + J_z^2 + \hbar J_z = J_+J_- + J_z^2 - \hbar J_z.
    \] Now, \[
        J^2\psi_{max} = (\beta_{max}^2 + \hbar\beta_{max})\psi_{max} =
        \alpha\psi_{max}, \qquad
        J^2\psi_{min} = (\beta_{min}^2 - \hbar\beta_{min})\psi_{min} =
        \alpha\psi_{min}.
    \] This gives $\beta_{max} = -\beta_{min}$ and $\beta_{max} = \beta_{min} +
    n\hbar$. Thus, \[
        \beta_{max} = \frac{1}{2}n\hbar.
    \] Writing $j = n /2$, we have \[
        \alpha = \hbar^2 j(j + 1), \qquad \beta = m_j\hbar, \qquad m_j = -j, -j + 1,
        \dots, j - 1, j.
    \] These are the eigenvalues of $\psi$ with respect to $J^2$ and $J_z$.
    Note that fermions (matter particles) correspond to odd $n$, and bosons (force
    particles) correspond to even $n$.

    \subsection{Orbital angular momentum}
    Recall that using spherical polar coordinates, we can write \[
        \grad{} = \ver\pp{}{r} +
        \veth\frac{1}{r}\pp{}{\theta} +
        \veph\frac{1}{r\sin\theta}\pp{}{\phi}.
    \] With this, we write \[
        L_x = i\hbar\left(\sin\phi\pp{}{\theta} +
        \cot\theta\cos\phi\pp{}{\phi}\right), \quad
        L_y = i\hbar\left(-\cos\phi\pp{}{\theta} +
        \cot\theta\sin\phi\pp{}{\phi}\right), \quad
        L_z = -i\hbar\pp{}{\phi}.
    \] Also, \[
        L^2 =
        -\hbar^2\left(\frac{1}{\sin\theta}\pp{}{\theta}\left(\sin\theta\pp{}{\theta}
        \right) + \frac{1}{\sin^2\theta}\pp[2]{}{\phi}\right), \qquad
        L_{\pm} = \hbar e^{\pm i\phi}\left(\pm\pp{}{\theta} +
        i\cot\theta\pp{}{\phi}\right).
    \] We want to have \[
        L^2 \psi_{lm} = \hbar^2 l(l + 1)\psi_{lm}, \qquad L_z\psi_{lm} =
        m\hbar\psi_{lm}.
    \] To solve these eigenvalue equations, we separate variables as $\psi(\theta,
    \phi) = \Theta(\theta) \Phi(\phi)$. The second equation thus gives \[
        \Phi(\phi) = e^{im\phi}, \qquad \psi_{lm} = \Theta e^{im\phi}.
    \] Note that $\psi_{lm}$ must be periodic in $\phi$ with period $2\pi$, which
    forces $m$ to be an integer. Plugging this into the first equation gives \[
        \left[\frac{1}{\sin\theta}\pp{}{\theta}\left(\sin\theta\pp{}{\theta}\right)
        - \frac{m^2}{\sin^2\theta} + l(l + 1)\right]\Theta(\theta) = 0.
    \] This is called a Legendre differential equation, whose solutions are the
    Legendre polynomials. The solutions $\psi_{lm} = Y_{lm}$ are called spherical
    harmonics. Each of the Legendre functions $P_{lm}(\xi)$ has $l - m$ roots
    within $|\xi| < 1$. The Legendre polynomials $P_l$ satisfy the recurrence \[
        (l + 1)P_{l + 1}(\xi) = (2l + 1)\xi P_{l}(\xi) - lP_{l - 1}(\xi).
    \] The Legendre functions satisfy \[
        P_{lm}(-\xi) = (-1)^{l + m} P_{lm}(\xi),
    \] \[
        \int_{-1}^{+1}P_{lm}(\xi)P_{l'm}(\xi)\:d\xi = \frac{2}{2l + 1}\cdot \frac{(l
        - m)!}{(l + m)!}\,\delta_{ll'}.
    \] It can also be shown that all $Y_{lm}$ are orthogonal and complete. Note that
    $Y_{lm}$ is even for even $l$ and odd for odd $l$.
    
    \subsection{The central potential problem}
    Consider a potential $V(r)$ which only depends on radial distance.
    Then, \[
        \hat{H} = \frac{\hat{p}^2}{2m} + V(r).
    \] We can calculate the norm of the orbital angular momentum, \[
        L^2 = r^2p^2 - (\vr \cdot \vp)^2 - i\hbar\,\vr\cdot\vp.
    \] This can be rearranged to get \[
        \vr\cdot\vp = -i\hbar r\pp{}{r}, \qquad 
        \hat{p}^2 = \frac{L^2}{r^2} + \hat{p}_r^2, \qquad
        \hat{p}_r^2 = -i\hbar \left(\frac{1}{r} + \pp{}{r}\right).
    \] Note that \[
        [r, \hat{p}_r] = i\hbar.
    \] This means that the Schr\"odinger equation looks like \[
        \left[-\frac{\hbar^2}{2m}\left(\pp[2]{}{r} + \frac{2}{r}\pp{}{r}\right) +
        \frac{L^2}{2mr^2} + V(r)\right]\psi(r, \theta, \phi) = E(r, \theta, \phi).
    \] Since $V(r)$ has rotational symmetry, we have $[\hat{H}, L^2] = 0$. Thus, we
    separate \[
        \psi(r, \theta, \phi) = R(r)\,Y_{lm}(\theta, \phi).
    \] Using $L^2Y_{lm} = \hbar^2l(l+1)Y_{lm}$ makes $Y_{lm}$ drop out of the
    equation. Taking $u(r) = rR(r)$, we have \[
        \left[-\frac{\hbar^2}{2m}\pp[2]{}{r} + \frac{\hbar^2}{2mr^2}l(l + 1) +
        V(r)\right]u(r) = Eu(r).
    \] We may define an effective potential as \[
        V_\text{eff}(r) = V(r) + \frac{\hbar^2}{2mr^2}l(l+1).
    \] Normalizability gives \[
        \int |u(r)|^2 \:dr < \infty, \qquad
        \lim_{r \to \infty} |u(r)| \leq \frac{a}{r^{1 /2 + \epsilon}}.
    \] In other words, $u(r)$ must fall off faster than $1 / \sqrt{r}$
    asymptotically. Similarly, $R(r) = u(r) / r$, so $u(r) \to 0$ faster as $r
    \to 0$. For $l \neq 0$, the centripetal part of the effective potential makes it
    repulsive overall. Otherwise, for $l = 0$, we must have $u(0) = 0$ so \[
        V_\text{eff}(r) = \begin{cases}
            V(r), &\text{ if } r > 0, \\
            \infty, &\text{ if } r = 0.
        \end{cases}
    \] 

    \section{The hydrogen atom}
    This is a simple two body problem with a negatively charged electron orbiting a
    positively charged nucleus.
    Here, our potential of interest is the Coulomb potential, \[
        V(r) = -\frac{e^2}{4\pi \epsilon_0 r}.
    \] Here, we define \[
        \vr_{cm} = \frac{m_1\vr_1 + m_2\vr_2}{m_1 + m_2}, \qquad
        \mu = \frac{m_1m_2}{m_1 + m_2}.
    \] We also have the relative variables \[
        \vr = \vr_1 - \vr_2, \qquad \vp = \mu(\vv_1 - \vv_2).
    \] We use $\mu$ and $\nu$ for the particle indices, and $i$ and $j$ for the
    Cartesian indices. Now, \[
        [r_{\nu i}, p_{\mu j}] = i\hbar \delta_{ij}\delta_{\mu\nu}, \qquad
        [\vr_{cm, i}, \vp_{cm, j}] = i\hbar \delta_{ij} = [r_i, p_j].
    \] Also, \[
        \vp_{cm} = -i\hbar\grad{}_{cm}, \qquad 
        \vp_{r} = -i\hbar\grad{}_{r}, \qquad
        \frac{p_1^2}{m_1} + \frac{p_2^2}{m_2} = \frac{p_{cm}^2}{m_1 + m_2} +
        \frac{p^2}{2\mu}.
    \] This gives us the Schr\"odinger equation \[
        \left[\frac{p_{cm}^2}{M} + \frac{p^2}{2\mu} + V(r)\right]\psi(\vr_{cm}, \vr)
        = E_{tot}\psi(\vr_{cm}, \vr).
    \] Note that the system as a whole acts as a free particle. Thus, \[
        E_{cm} = \frac{\hbar^2k_{cm}^2}{2M}, \qquad \psi_{cm}(\vr_{cm}) =
        e^{-\vk_{cm}\cdot\vr_{cm}}
    \] We are left with \[
        \left[\frac{p^2}{2\mu} + V(r)\right]\psi(\vr)
        = E_{rel}\psi(\vr),
    \] where $E_{rel} = E_{tot} - E_{cm}$.
    Using our results from the central potential problem, \[
        \left[-\frac{\hbar^2}{2\mu}\dd[2]{}{r} + \frac{\hbar^2}{2\mu r^2}l(l + 1)
        - \frac{e^2}{4\pi\epsilon_0 r}\right]u(r) = E_{rel} u(r).
    \] When $l = 0$, we have \[
        V_{\text{eff}}(r) \to -\frac{e^2}{4\pi \epsilon_0 r} < 0.
    \] Thus, we have bound states for $l = 0$, $E < 0$. Setting $\epsilon = -E$, we
    have \[
        \dd[2]{}{r}u(r) + \frac{2\mu e^2}{4\pi\epsilon_0 \hbar^2 r}u(r) - \frac{l(l
        + 1)}{r^2}u(r) = \frac{2\mu\epsilon}{\hbar^2}u(r).
    \] As $r \to \infty$, we set $u \sim u_{app}$, and \[
        \dd[2]{}{r}u_{app} = \frac{2\mu \epsilon}{\hbar^2}u_{app}, \qquad
        u_{app}(r) = e^{-\sqrt{2\mu\epsilon / \hbar^2}r}.
    \] We now attempt a trial solution $u(r) = v(r)u_{app}(r)$, and expand this as a
    power series \[
        u(r) = v(r)\,e^{-\sqrt{2\mu\epsilon / \hbar^2}r}, \qquad 
        v(r) = \sum_{p = 1}^\infty A_p r^p.
    \] Note that $A_0 = 0$ since $u(0) = 0$. This will give \[
        \left[p(p + 1) - l(l + 1)\right]A_{p + 1} =
        \left[\frac{2p\sqrt{2\mu\epsilon}}{\hbar} - \frac{2\mu
        e^2}{4\pi\epsilon_0\hbar^2}\right]A_p.
    \] Note that for $p = l$, $A_p = 0$. This kills all preceding coefficients, so
    the only non-zero coefficients are for $p > l$. Also, $u(r) \to 0$ as $r \to
    \infty$, so the power series of $v(r)$ must terminate. Setting $A_{n + 1} = 0$,
    we demand \[
        \frac{2n\sqrt{2n\epsilon}}{\hbar} = \frac{2\mu e^2}{4\pi\epsilon_0 \hbar^2}.
    \] Rearranging, \[
        E = -\epsilon = -\frac{\mu e^4}{2(4\pi\epsilon_0)^2\hbar^2 n^2} \approx
        -\frac{13.6}{n^2}\si{\eV}.
    \] Also, \[
        R(r) = -\frac{v(r)}{r}e^{-\sqrt{2\mu\epsilon / \hbar^2}r} = R_{nl}(r),
    \] so we recover $\psi_{nlm} = R_{nl}Y_{lm}$. An important parameter is the Bohr
    radius, given by \[
        a_0 = \frac{4\pi\epsilon_0 \hbar^2}{\mu e^2} \approx \SI{5.3e-11}{\m}.
    \] Summarizing, the good quantum numbers are \[
        n = 1, 2, 3, \dots, \qquad l = 0, 1, \dots, n - 1, \qquad m = -l, -l + 1,
        \dots, l - 1, l.
    \] Note that the energy $E_n$ depends on the principal quantum number $n$ alone!
    Each $n$ has $n$ possible $l$, and each $l$ has $2l + 1$ possible $m$.
    Thus, the total degeneracy of $E$ is $\sum_{l = 0}^{n - 1} 2l + 1 = n^2$. This
    is doubled to account for the spin internal degree of freedom.

    \section{Spin angular momentum}
    \subsection{The Zeeman effect}
    Consider a hydrogen atom in an external magnetic field $B$ aligned along the $z$
    axis. If $H_0$ is the Hamiltonian of the Hydrogen atom, then the effective
    Hamiltonian is given by \[
        H = H_0 - \frac{e}{2m}\ve{B}\cdot\vL_{\text{eff}}.
    \] This modifies the Schr\"odinger equation slightly, giving \[
        E_{nlm} = -\frac{13.6}{n^2}\si{\eV} - \hbar\omega_Lm_{\text{eff}}.
    \] The term $\omega_L = eB / 2m$ is called the Larmor frequency. What this means
    is that the presence of the magnetic field ought to lift the $2n + 1$ degeneracy
    of the energy levels.

    On the other hand, the actual observed splitting in a hydrogen atom is
    different, with an even number of levels. This indicates the presence of another
    source of angular momentum, called \textit{spin}. 

    \subsection{Stern-Gerlach experiment}
    A beam of particles splits into two patches when subjected to an inhomogeneous
    magnetic field. We do not observe $2l + 1$ beams however, but an even number
    (two times what we expect). Again, this points to the existence of the spin
    angular momentum, with \[
        \ve{\mu}_S = -\frac{g_S\mu_B}{\hbar}\ve{S}.
    \] 

    \subsection{Formalism}
    We have \[
        [S_i, S_j] = i\hbar \delta_{ij}\epsilon_{ijk}S_k.
    \] Also, \[
        S^2\ket{s, m} = s(s + 1)\ket{s, m}, \qquad S_z\ket{s, m} = m\ket{s, m}.
    \] We also have the creation and annihilation operators, \[
        S_\pm = S_x \pm iS_y, \qquad
        S_\pm\ket{s, m_s} = \hbar\sqrt{s(s + 1) - m_s(m_s + 1)}\ket{s, m_s \pm 1}.
    \] Suppose $S = 1 /2$. Now, there are two corresponding $m_s$, so we have two
    eigenstates. \[
        S_z\ket{\uparrow} = \frac{1}{2}\hbar \ket{\uparrow}, \qquad
        S_z\ket{\downarrow} = \frac{1}{2}\hbar \ket{\uparrow}.
    \] These can be represented using two orthogonal vectors, \[
        \ket{\uparrow} = \ket{s = 1 /2, m_s = +1 / 2} = \begin{pmatrix}
            1\\0
        \end{pmatrix},\qquad
        \ket{\downarrow} = \ket{s = 1 /2, m_s = -1 / 2} = \begin{pmatrix}
            0\\1
        \end{pmatrix}.
    \] The duals are given by the transposes. Now, the operators $S_i$ can also be
    given matrix representations, whose components can be computed using the
    projections \[
        \braket{\uparrow|S_z|\downarrow} = \frac{1}{2}\hbar, \qquad
        \braket{\downarrow|S_z|\uparrow} = -\frac{1}{2\hbar}, \qquad
        \braket{\uparrow|S_z|\uparrow} = \braket{\downarrow|S_z|\downarrow} = 0.
    \] Thus, \[
        S_z = \frac{1}{2}\hbar \begin{pmatrix}
            1 & 0 \\ 0 & -1
        \end{pmatrix}.
    \] Similarly, we can show that \[
        S_+ = \hbar \begin{pmatrix}
            0 & 1 \\ 0 & 0
        \end{pmatrix}, \qquad
        S_- = \hbar \begin{pmatrix}
            0 & 0 \\ 1 & 0
        \end{pmatrix}.
    \] We can now obtain $S_x$ and $S_y$, \[
        S_x = \frac{1}{2}\hbar \begin{pmatrix}
            0 & 1 \\ 1 & 0
        \end{pmatrix}, \qquad
        S_y = \frac{1}{2}\hbar \begin{pmatrix}
            0 & -i \\ i & 0
        \end{pmatrix}.
    \] 
    
\end{document}
% vim: set tabstop=4 shiftwidth=4 softtabstop=4:
