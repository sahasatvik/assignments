\documentclass[10pt]{article}

\usepackage[T1]{fontenc}
\usepackage{geometry}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{cancel}
\usepackage{xcolor}

\title{Probability I - Assignment VII}
\author{Satvik Saha}
\date{}

\geometry{a4paper, margin=1in}
\setlength\parindent{0pt}
\renewcommand{\labelenumi}{(\alph{enumi})}
\renewcommand\CancelColor{\color{red}}
% \renewcommand\qedsymbol{$\blacksquare$}
\newcounter{prob}
\def\problem{\stepcounter{prob}\paragraph{Exercise \arabic{prob}}}
\def\solution{\paragraph{Solution}}

\newcommand\op[1]{\operatorname{#1}}
\newcommand\E[1]{\op{E}[#1]}
\newcommand\V[1]{\op{Var}[#1]}
\newcommand\CV[1]{\op{Cov}[#1]}

\newtheorem*{lemma}{Lemma}

\begin{document}
        \par\textbf{IISER Kolkata} \hfill \textbf{Assignment VII}
        \vspace{3pt}
        \hrule
        \vspace{3pt}
        \begin{center}
                \LARGE{\textbf{MA 2202 : Probability I}}
        \end{center}
        \vspace{3pt}
        \hrule
        \vspace{3pt}
        Satvik Saha, \texttt{19MS154}, Group D\hfill\today
        \vspace{20pt}

        \problem Let $X$ and $Y$ be jointly distributed continuous random variables.
        Let the marginal distribution of $Y$ be standard normal. If \[
            \E{X | Y} = 10Y^4 - 2Y^3 + 5Y^2 - 4Y + 3,
        \] determine $\E{X}$.
        
        \solution We use the formula \[
            \E{\E{X | Y}} = \E{X}
        \] to write \[
            \E{X} = 10\E{Y^4} - 2\E{Y^3} + 5\E{Y^2} - 4\E{Y} + 3.
        \] Now for a standard normal distribution, recall that the moments are given
        by \[
            \E{Y^{2n - 1}} = 0, \qquad \E{Y^{2n}} = (2n - 1)!!,
        \] so the required expectation is \[
            \E{X} = 10\cdot 3\cdot 1 + 5\cdot 1 + 3 = 38.
        \] 

        \problem Let $X$ and $Y$ be independent identically distributed
        $\op{Poisson}(\lambda)$ random variables. Let $Z = \min(X, Y)$ and $W =
        \max(X, Y)$.
        \begin{enumerate}
            \itemsep0em
            \item Determine the correlation coefficient of $Z + W$ and $X - Y$.
            \item Write down the joint probability mass function of $Z$ and $W$.
            \item Compute $\E{Z | W}$.
        \end{enumerate}

        \solution \begin{enumerate}
            \itemsep0em
            \item Note that $X + Y = Z + W$, since the sum of the maximum and
            minimum is always the sum of the two. Recall that the probability mass
            function of a Poisson random variable \[
                p_X(x) = p_Y(x) = \frac{\lambda^n}{n!}e^{-\lambda},
            \] for $n \geq 0$, and $\E{X} = \E{Y} = \lambda$. Therefore, \[
                \E{X + Y} = 2\lambda, \qquad \E{X - Y} = 0.
            \] Also, \[
                \CV{X + Y, X - Y} = \E{(X + Y)(X - Y)} - \E{X + Y}\E{X - Y} = \E{X^2
                - Y^2} = 0.
            \] Thus, the correlation coefficient is simply \[
                \rho_{X + Y, X - Y} = \frac{\CV{X + Y, X - Y}}{\sigma_{X + Y}
                \sigma_{X - Y}} = 0.
            \] 
            \item Recall that since $X$ and $Y$ are independent, \[
                P(X = m, Y = n) = P(X = n, Y = m) = p_X(m) p_Y(n) = \frac{\lambda^{m
                + n}}{m!n!}e^{-2\lambda}.
            \] We have also shown that \[
                p_{Z, W}(m, n) = \begin{cases}
                    P(X = m, Y = n), &\text{ if } 0 \leq m \leq n, \\
                    0, &\text{ otherwise}.
                \end{cases}
            \] This is simply because $Z \leq W$. Now, if $0 \leq m < n$, then \[
                p_{Z, W}(m, n) = P(X = m, Y = n) + P(X = n, Y = m) =
                \frac{2\lambda^{m + n}}{m!n!}e^{-2\lambda}.
            \] If $m = n$, then simply \[
                p_{Z, W}(m, m) = P(X = m, Y = m) =
                \frac{\lambda^{2m}}{(m!)^2}e^{-2\lambda}.
            \] Thus, \[
                p_{Z, W}(m, n) = \begin{cases}
                    \frac{2\lambda^{m + n}}{m!n!}e^{-2\lambda}, &\text{ if } 0 \leq
                    m < n, \\
                    \frac{\lambda^{2m}}{(m!)^2}e^{-2\lambda}, &\text{ if } 0 \leq m
                    = n, \\
                    0, &\text{ otherwise}.
                \end{cases}
            \]  

            \item Set $V = \E{Z | W}$. Note that \[
                P(Z = m | W = n) = \frac{P(Z = m, W = n)}{P(W = n)}.
            \] We thus compute the probability mass function of $W$. Now, \[
                P(W \leq n) = P(X \leq n, Y \leq n) = P(X \leq n)^2.
            \] This gives, \begin{align*}
                P(W = n) &= P(W \leq n) - P(W \leq n - 1) \\
                &= P(X \leq n)^2 - P(X \leq n - 1)^2 \\ 
                &= \left[P(X \leq n) + P(X \leq n - 1)\right]\cdot P(X = n).
            \end{align*}
        \end{enumerate}
\end{document}
