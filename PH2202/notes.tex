\documentclass[11pt]{article}

\usepackage[T1]{fontenc}
\usepackage{geometry}
\usepackage{amsmath, amssymb, amsthm}
\usepackage[%
    hidealllines=true,%
    innerbottommargin=15,%
    nobreak=true,%
]{mdframed}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage[hidelinks]{hyperref}
\usepackage{fancyhdr}
\usepackage{lipsum}
\usepackage{bm}
\usepackage{siunitx}
\usepackage[scr=boondoxupr]{mathalpha}

\geometry{a4paper, margin=1in, headheight=14pt}

\pagestyle{fancy}
\fancyhf{}
\renewcommand\headrulewidth{0.4pt}
\fancyhead[L]{\scshape PH2202: Thermal physics}
\fancyhead[R]{\scshape \leftmark}
\rfoot{\footnotesize\it Updated on \today}
\cfoot{\thepage}

\def\C{\mathbb{C}}
\def\R{\mathbb{R}}
\def\Q{\mathbb{Q}}
\def\Z{\mathbb{Z}}
\def\N{\mathbb{N}}
% \newcommand\ve[1]{\boldsymbol{#1}}
\newcommand\ve[1]{\vec{#1}}
\newcommand\ddx[1]{\frac{d #1}{d x}}
\newcommand\ddt[1]{\frac{d #1}{d t}}
\newcommand\dd[3][]{\frac{d^{#1}{#2}}{d {#3}^{#1}}}
\newcommand\ppx[1]{\frac{\partial #1}{\partial x}}
\newcommand\ppt[1]{\frac{\partial #1}{\partial t}}
\newcommand\pp[3][]{\frac{\partial^{#1}{#2}}{\partial {#3}^{#1}}}
\newcommand\norm[1]{\left\lVert#1\right\rVert}
\newcommand\grad[1]{\ve{\nabla}#1}
\newcommand\divg[1]{\ve{\nabla}\cdot#1}
\newcommand\curl[1]{\ve{\nabla}\times#1}
\newcommand\lapl[1]{\nabla^2 #1}
\newcommand\E[1]{\langle #1 \rangle}

\newmdtheoremenv[%
    backgroundcolor=blue!10!white,%
]{theorem}{Proposition}[section]
% \newmdtheoremenv[%
%     backgroundcolor=violet!10!white,%
% ]{corollary}{Corollary}[theorem]
% \newmdtheoremenv[%
%     backgroundcolor=teal!10!white,%
% ]{lemma}[theorem]{Lemma}

\theoremstyle{definition}
\newmdtheoremenv[%
    backgroundcolor=green!10!white,%
]{definition}{Definition}[section]
% \newmdtheoremenv[%
%     backgroundcolor=red!10!white,%
% ]{exercise}{Exercise}[section]
\newmdenv[%
    hidealllines=false,%
    linecolor=black!20!white,%,
    % backgroundcolor=cyan!5!white,%
    innertopmargin=10,%
]{equationbox}
\newenvironment{boxedeq}%
    {\begin{equationbox}\begin{equation}}%
    {\end{equation}\end{equationbox}}
\newenvironment{boxedeq*}%
    {\begin{equationbox}\begin{equation*}}%
    {\end{equation*}\end{equationbox}}

\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\newtheorem*{example}{Example}

\numberwithin{equation}{section}

\title{
    \Large\textsc{PH2202} \\
    % \vspace{10pt}
    \Huge \textbf{Thermal physics} \\
    \vspace{5pt}
    \Large{Spring 2021}
}
\author{
    \large Satvik Saha%
    % \thanks{Email: \tt ss19ms154@iiserkol.ac.in}
    \\\textsc{\small 19MS154}
}
\date{\normalsize
    \textit{Indian Institute of Science Education and Research, Kolkata, \\
    Mohanpur, West Bengal, 741246, India.} \\
    % \vspace{10pt}
    % \today
}

\begin{document}
    \maketitle

    Thermal physics deals with the topic of \textit{temperature}.
    Temperature is a statistical property -- thus, it makes no sense to talk of the
    temperature of one, two, or even a handful of particles.

    \tableofcontents

    \section{Kinetic Theory of Gases}
    \subsection{The molecular picture of matter}
    Imagine looking into a container filled with steam, and magnifying by a factor
    of \num{e10}. A cubic metre might contain around \num{20} molecules, all of
    which are in constant motion, colliding with the walls and each other.
    Suppose that one of the walls is a piston. The molecules which collide with the
    piston and impart a force on it; in order to fix the piston in place, a
    counter force must be applied.
    \begin{definition}[Pressure]
        The force per unit area applied by a gas on the walls of its container is
        called the pressure of the gas.
    \end{definition}
    Now provide the system with heat. We know that the temperature of the gas must
    increase -- what this means is that the speeds of the molecules increase, on
    average.
    \begin{definition}[Temperature]
        The temperature of a gas is a measure of the average kinetic energy of the
        constituent particles.
    \end{definition}
    Instead, consider an adiabatic container, which stops all flow of heat into and
    out of the gas. By compressing the gas with the piston, we observe that the
    temperature of the gas also rises.

    Now, take away heat from the system. The temperature drops and the molecules
    tend to be close to each other. This is because of the dipolar attractive forces
    between the molecules (which varies as the inverse cube of the distance of the
    dipoles, and is hence comparatively short range).
    On the other hand, they cannot get too close, since once the electron clouds of
    the molecules start to overlap, a repulsive force is introduced. At a certain
    point, we reach a condensed form of matter: liquid water.

    Liquid water is very much incompressible, yet the molecules freely move and
    slide around, without any periodic arrangement. The molecules at the surface are
    attracted by like molecules inside; this cohesive force keeps the liquid 
    condensed. This tendency of a liquid to minimize its surface area is related to
    the phenomenon of surface tension. Some molecules on the surface are energetic
    enough to escape this cohesive attraction and leave the liquid -- this is called
    evaporation. Heating a liquid simply increases the average kinetic energy of the
    molecules, thus increasing the rate of evaporation.
    When these energetic molecules leave the liquid, the average kinetic energy of
    the liquid drops, hence it cools down. This is the phenomenon of latent heat.

    When this happens in a closed container, the process of evaporation cannot go on
    indefinitely, since the air has a limited capacity for holding moisture.
    Condensation is the process where these airborne molecules return to the liquid.
    At a certain point, the rates of evaporation and condensation become equal, and
    we obtain a saturated vapour.

    Return to the liquid, and take away even more heat. Now, the motion of the
    molecules decrease to a point where they occupy fixed positions. They are still
    in motion, but their movement is restricted around their mean position.
    This is the crystal state. The lower the temperature, the smaller the
    oscillations and vibrations.

    \subsection{Basic assumptions}
    \begin{enumerate}
        \itemsep0em 
        \item Gases are made up of a large number of molecules, and all molecules of
        one gas are identical.
        \item Molecules of a gas are always moving. The number of molecules per unit
        volume remains constant, i.e.\ the density remains constant.
        \item Molecules behave as elastic spheres during collisions. Kinetic energy
        and momenta are conserved, and the collision time is negligible compared to
        the free path time.
        \item No force acts on any molecule, except during collisions.
        Intermolecular forces are only short ranged. Between collisions, the
        molecules continue moving with uniform velocity in a straight line.
        \item The entire gas is isotropic; for all molecules, all directions are the
        same.
    \end{enumerate}

    \begin{remark}
        The collisions between molecules can be modelled as the elastic collision of
        hard spheres. The repulsive forces between molecules, governed by the
        Lennard-Jones potential, varies as $1 /r^{12}$, which is very short
        range and very powerful.
        In comparison, gravity is a long range force since it varies as $1 /r^2$.
    \end{remark}
    
    \subsection{Ideal gases}
    For an ideal gas, we make a few more assumptions. The gas molecules have
    negligible size, so are essentially point masses. Also, there are no forces on
    the molecules except during collisions, so they have no potential.

    No real gases are ideal. We may look at the limit where the temperature $T$ is
    very high and the density (or $n$) is very low. Here, the kinetic energy far
    exceeds any potential energies, and the mean free path becomes very high.

    We look at some absurdities of this model.
    \begin{enumerate}
        \itemsep0em
        \item How do point masses collide?
        \item If two gases of different temperatures are mixed, how do they exchange
        heat?
        \item Without intermolecular forces, are there any phase changes?
        \item How do we explain properties such as viscosity and thermal
        conductivity?
    \end{enumerate}

    \subsection{Pressure}
    Suppose that a volume $dV$, located at $(r, \theta, \phi)$, contains $n\:dV$
    particles. If we consider a small flat, horizontal area $\Delta S$, we can
    calculate the number of molecules moving towards $\Delta S$, as \[
        dN = \frac{n\cos\theta\,\Delta S}{4\pi r^2}\:dV.
    \] Over a time $\Delta t$, we only consider the particles within the region 
    $r = 0 \to c\Delta t$ above the $xy$ plane. Integrating, we have \[
        \int dN = \int_0^{c\Delta t}\int_{0}^{\pi /2}\int_0^{2\pi}
        \frac{n\cos\theta\,\Delta S}{4\pi r^2} r^2\sin\theta\:d\phi\:d\theta\:dr.
    \] Simplifying, we have \[
        N = \frac{1}{2} n\,\Delta S \cdot c\Delta t \cdot \int_0^{\pi /2}
        \cos\theta\sin\theta \:d\theta = \frac{1}{4}nc\Delta S \,\Delta t.
    \] Thus, the number of molecules hitting the wall per unit area per unit time is
    given by $nc/4$.

    What if we have different molecules with different velocities? We can use this
    expression to conclude that if $n_i$ molecules have velocity $c_i$, the average
    velocity is $\E{c} = \sum n_ic_i / n$, $n = \sum n_i$, so \[
        N = \frac{1}{4}n\E{c}.
    \] Now, each molecule can strike the walls of the container at some angle
    $\theta$. For an elastic collision, the change in its momentum is
    $2mc\cos\theta$. Repeating the integration process, we write the momentum
    imparted as \[
        \int 2mc\cos\theta \cdot\frac{n\cos\theta \Delta S}{4\pi r^2} dV =
        mnc^2\Delta S \cdot \int_0^{\pi /2}\cos^2\theta\sin\theta\:d\theta.
    \] Simplifying, we have \[
        \frac{1}{3}mnc^2\Delta S \Delta t.
    \] For a velocity distribution, we deal with the RMS velocity where $c_{rms}^2 =
    \E{c_i^2} = \sum n_ic_i^2 / n$. Thus the pressure, which is the momentum
    imparted per unit area per unit time, is given by
    \begin{boxedeq*}
        p = \frac{1}{3}\rho c_{rms}^2.
    \end{boxedeq*}
    Note that $\rho = mn$ is the density of the gas.
    Now, with knowledge of Boyle's Law and Charles' Law, we are forced to conclude
    that the temperature $T$ is linearly dependent on $c_{rms}^2$.

    For a volume $V$ of gas, we see that \[
        pV = \frac{1}{3}mnVc_{rms}^2 = \frac{1}{3}mNc_{rms}^2,
    \] where $N = nV$ is the total number of molecules. Now, the average kinetic
    energy of these $N$ molecules is \[
        E = \sum \frac{1}{2}mn_ic_i^2 = \frac{1}{2}mN c_{rms}^2.
    \] Combining these relations, we have \[
        pV = \frac{2}{3} E.
    \] 

    \begin{theorem}[Dalton's law of partial pressure]
        If there are multiple ideal gases in a container, then the total pressure of
        the mixture is the sum of partial pressures produced by each gas.\[
            p = p_1 + \dots + p_n = \sum \frac{1}{3} \rho_i \E{c^2}_i.
        \] 
        \begin{remark}
            This is a consequence of the assumption that the different gases do not
            interact with one another in any way, so the pressures they apply on the
            walls of the container simply add up. Similarly, the overall density is
            simply the sum $\rho = \rho_1 + \dots \rho_n$.
        \end{remark}
    \end{theorem}

    Consider two gases at the same pressure. Thus, we have \[
        n_1\epsilon_1 = n_2\epsilon_2,
    \] where $\epsilon$ is the average kinetic energy of the gas. This is a measure
    of the temperature $T$ of the gas. Since the gas molecules collide, the
    temperature $T$ must be common between the two gases, so $\epsilon_1 =
    \epsilon_2$. This in turn means $n_1 = n_2$.
    
    \begin{theorem}[Avogadro's law]
        Equal volumes of two ideal gases at the same pressure and temperature will
        contain the same number of particles.
    \end{theorem}

    \begin{theorem}[Boyle's law]
        For isothermal expansion or contraction of a gas, \[
            pV = \text{constant}.
        \] 
    \end{theorem}

    For 1 mole of a gas, introduce the constant $R$ such that \[
        pV = \frac{2}{3}E = RT.
    \] Putting $E = N_A\epsilon$, we write \[
        \epsilon = \frac{3}{2}k_B T.
    \] Here, $k_B = R / N_A$ is the Boltzmann constant. $N_A$ is called Avogadro's
    number, which is the number of particles in 1 mole of a gas. We note that \[
        N_A \approx \num{6.022e23}, \qquad 
        k_B \approx \SI{1.38e-23}{\joule\per\kelvin}.
    \] 
    Combining all these ideas leads to the ideal gas law.

    \begin{theorem}[Ideal gas law]
        The ideal gas law gives a relation between the pressure $p$, the volume $V$,
        the temperature $T$, and the number of moles $n$ of an ideal gas.
        \[
            pV \,=\, nRT.
        \]
        Here, the constant of proportionality $R$ is called the ideal gas constant,
        with value \[
            R \,\approx\, \SI{8.314}{\joule\per\mole\per\kelvin}.
        \]
    \end{theorem}

    Observe that the average energy of a molecule is \[
        \epsilon = \frac{1}{2}m c_{rms}^2 = \frac{3}{2}k_B T.
    \] This leads to
    \begin{boxedeq*}
        p = \frac{1}{3}mn c_{rms}^2 = n k_B T,
    \end{boxedeq*}
    which shows that the pressure $p$ of an ideal gas is a pure function of the
    intensive properties $n$ and $T$.

    \subsection{Mean free path}
    We can relax the assumption that gas molecules are point masses, instead
    modelling them as hard spheres. If we know the molar mass $M$ and the density
    $\rho$ of the gas, the volume occupied per molecule is $M / N_A\rho$.
    In this way, we can approximate the `diameter' of each molecule, say $\sigma$.
    If the molecules are packed tetrahedrally, say in the liquid state, each
    molecule occupies a volume $\sigma^3 / \sqrt{2}$. Thus, we write \[
        \frac{M}{N_A \rho} = \frac{\sigma^3}{\sqrt{2}}, \qquad
        \sigma = \left(\frac{\sqrt{2} M}{ N_A \rho}\right)^{1 /3}.
    \]

    \begin{definition}
        The mean distance travelled by a molecule between successive collisions is
        called the mean free path.
    \end{definition}

    Consider a gas with identical molecules, each with diameter $\sigma$.  Suppose
    that a particular molecule moves with relative speed $v$ with respect to the
    other molecules. During each collision, the centres of the molecules are
    separated by $\sigma$. As this molecule moves, it sweeps out a cylindrical
    volume of influence, with area of cross section $\pi \sigma^2$ -- any other
    molecules lying within this volume are vulnerable to collision. With respect to
    them, we see that within a time $\Delta t$, this volume is given by $\pi
    \sigma^2 v\Delta t$. Multiplying by the number density $n$, we see that
    $n\pi\sigma^2 v\Delta t$ molecules lie within this volume. We set this to be the
    number of collisions experienced by our molecule over the time $\Delta t$. If
    our molecule has an actual speed of $u$, it must have travelled a distance $u
    \Delta t$. This means that the average path length between collisions is given
    by
    \begin{boxedeq*}
        \lambda = \frac{u\Delta t}{n\pi \sigma^2 v \Delta t} = \frac{u /
        v}{n\pi\sigma^2}.
    \end{boxedeq*}
    Now, if our particle of interest is moving significantly faster than all other
    surrounding molecules, we may write $u /v \approx 1$, so $\lambda \approx 1
    /n\pi\sigma^2$. Otherwise, set $u = c$, which is the common speed of all gas
    molecules. If two such molecules move with the same speed but in different
    directions, separated by an angle $\theta$, their relative speed is given by \[
        v = 2c\sin\frac{\theta}{2}.
    \] To average this over $\theta$, we first need to find the probability
    distribution for $\theta$. Note that if we direct the velocity of one of the
    molecules along the axis of a sphere, the other velocity can pierce the sphere
    surface at any point with uniform probability; this is due to the isotropic
    nature of the gas. Recall that a differential surface element on a sphere is
    given by \[
        dS = R^2\sin\theta \:d\theta \:d\phi.
    \] Thus, the annular ring at $\theta$ has area $2\pi R^2 \sin\theta \:d\theta$.
    Dividing by the total surface area $4\pi R^2$, we see that $\theta$ is
    distributed with the probability density function $f(\theta) = \sin\theta /2$.
    Thus, the average value of the relative speed $v$ is given by \[
        \E{v} = \int_0^\pi 2c \sin\frac{\theta}{2}\cdot \frac{1}{2} \sin\theta 
        \:d\theta = \frac{4}{3}c.
    \] This gives the mean free path expression \[
        \lambda = \frac{3}{4n\pi\sigma^2}.
    \] This expression is contingent on the assumption that all molecules move with
    identical speed, in an isotropic fashion. A more nuanced calculation using the
    Maxwell distribution gives the expression
    \begin{boxedeq*}
        \lambda = \frac{1}{\sqrt{2}n\pi \sigma^2}.
    \end{boxedeq*}
    Note that this doesn't show any explicit dependence on the temperature $T$.
    On the other hand, short range interactions between molecules become more
    significant at low $T$, which increases the effective diameter $\sigma$.
    Conversely, this attraction diminishes at higher $T$. We may write \[
        \sigma^2 = \sigma_\infty^2 \left(1 + \frac{b}{T}\right),
    \] where $\sigma_\infty$ is the effective diameter as $T \to \infty$, and $b$ is
    a measure of the molecular attraction. Thus, \[
        \lambda \propto \frac{1}{1 + \frac{b}{T}},
    \] which shows a marginal dependence on $T$. \\

    Suppose that the probability that a molecule suffers no collisions over a
    distance $x$ is given by $f(x)$. Now, the homogeneity and isotropy of the gas
    means that over a distance $dx$, the probability of a collision will be some
    $p\:dx$, irregardless of the direction of $dx$ -- the proportionality is given
    by a constant $p$ when we consider very small $dx$. Now, the molecule suffers no
    collisions over a distance $x + dx$ with probability $f(x) (1 - p\:dx)$.
    However, this is just $f(x + dx)$, which we expand as a Taylor series and take
    only the first order terms to obtain $f(x) + f'(x)\:dx$. Thus, \[
        f' = -pf,
    \] which is solved by the exponential function $e^{-px}$. Since we want $f(0) =
    1$, i.e.\ no collisions whatsoever over a distance $0$, we set $f(x) = e^{-px}$.
    Now, we see that the probability of collision between $x$ and $x + dx$ is $f(x)
    \,p\:dx$, so the mean free path is simply the expected value \[
        \lambda = \int_{0}^\infty x\,e^{-px}\,p\:dx = \frac{1}{p}.
    \] Thus, the probability density function $f_\lambda$ of the free path is
    given as 
    \begin{boxedeq*}
        f_\lambda(x) = \frac{1}{\lambda}\, e^{- x / \lambda}.
    \end{boxedeq*}
    Note that this is an exponential distribution, with mean $\lambda$ and variance
    $\lambda^2$. Around $37\%$ of free paths are longer than $\lambda$; only $1\%$
    of paths are longer than $4.6\lambda$.

    \subsection{Pressure, considering collisions}
    We recall that the number of molecules moving from a volume $dV$ towards a
    surface $\Delta S$ was given by \[
        dN = \frac{n\cos\theta\,\Delta S}{4\pi r^2}\:dV.
    \] In our prior calculations, we neglected the effects of collisions. We show
    that these considerations do not in fact change the final result. Note that due
    to collisions, some of those molecules from $dV$ directed towards $\Delta S$ are
    deviated from their path and do not reach their destination. Additionally, other
    molecules from outside $dV$ can collide and reach $\Delta S$.

    Consider those molecules with speeds between $c$ and $c + dc$, say $dn_c$ many
    of them per unit volume. These molecules have a mean free path of $\lambda_c$,
    so any one of these will suffer $c \Delta t/ \lambda_c$ collisions over a times
    $\Delta t$. Thus, within a volume $dV$, the number of collisions in which those
    $dn_c$ molecules participate is given as \[
        \frac{c \Delta t}{\lambda_c} \:dn_c\:dV.
    \] Note that this must be the number of free paths which start over that time.
    From the isotropic nature of the gas, the fraction of those free paths which
    start towards $\Delta S$ is given as \[
        \frac{\cos\theta \Delta S}{4\pi r^2}.
    \] Of these, the $e^{- r / \lambda_c}$ fraction of free paths are longer than
    $r$, and hence reach $\Delta S$. Thus, the number of molecules which start from
    $dV$ and reach $\Delta S$ has the distribution \[
        dN_c = \frac{\cos\theta \Delta S}{4\pi r^2}\cdot \frac{c\Delta
        t}{\lambda_c}\cdot e^{-r / \lambda_c}\,\:dn_c\:dV.
    \] Integrating this over all space, and over all possible speeds $c = 0 \to
    \infty$, we obtain the familiar result \[
        N = \frac{1}{4}n\E{c} \cdot \Delta S\Delta t,
    \] only this time, we must define the average speed as \[
        \E{c} = \frac{1}{n}\int_0^\infty c\:dn_c.
    \] We redo the calculations for the pressure of the gas by noting that each
    molecule imparts a momentum change of $2mc\cos\theta$ to the container walls.
    Integrating, we get back our expression for pressure, \[
        p = \frac{1}{3}mn\E{c^2},
    \] where we redefine the root mean square speed $c_{rms}^2 = \E{c^2}$ as \[
        \E{c^2} = \frac{1}{n}\int_0^\infty c^2\:dn_c.
    \] Thus, our earlier results remain unchanged, even when accounting for
    collisions between different gas molecules.
    

    \subsection{Maxwell-Boltzmann distribution}
    The Maxwell-Boltzmann distribution gives the probability distribution of the
    velocities of ideal gas molecules. As a result, this depends on the isotropy of
    the gas, which includes the independence of the spatial components of velocity.
    This means that there is no correlation between the orthogonal components of the
    velocity of a gas molecule.

    Consider the velocity space of the molecules of an ideal gas. A gas molecule
    with velocity $\ve{c}$ can be identified with coordinates $(c_x, c_y, c_z)$ in
    this velocity space. Note that each of these components are independently
    distributed, i.e.\ the distribution of $c_x$ is a function only of $c_x$, and so
    on. Since all directions are equivalent, our choice of coordinate system being
    arbitrary, we assign the same probability density function $f$ to each of these
    components. Thus, the number of molecules whose velocities are in the cuboid
    $c_x \to c_x + dc_x$, $c_y \to c_y + dc_y$, $c_z \to c_z + dc_z$ is described by
    the joint probability distribution \[
        dN_c = N\, f(c_x)f(c_y)f(c_z)\:dc_x\:dc_y\:dc_z = N F(c)\:d\gamma,
    \] where $d\gamma = c^2\sin\theta\:dc\:d\theta\:d\phi$.
    The last step follows since the distribution must be independent of our
    choice of coordinates, hence depend only on the speed $c$. For fixed $c$, we
    have fixed $c^2 = c_x^2 + c_y^2 + c_z^2$ and fixed $F(c) = f(c_x)f(c_y)f(c_z)$.
    Now, the equilibrium distributions are such that entropy is maximized, which
    entails maximising the logarithm of $F(c)$.  In other words, we must maximise
    $g(\vec{c}) = \ln{F(c)}$ given the constraint $h(\ve{c}) = c^2 - c_x^2 - c_y^2 -
    c_z^2 = 0$. Using the method of Lagrange multipliers, we set \[
        \grad{g} = \lambda \grad{h},
    \] which gives the three equations \[
        \frac{f'(c_i)}{f(c_i)} + \lambda c_i = 0.
    \] These gives us exponential distributions of the form \[
        f(c_i) = a e^{-c_i^2 / \alpha^2}.
    \] Thus, the joint distribution is given by the product \[
        F(c) = a^3e^{-(c_x^2 + c_y^2 + c_z^2) /\alpha^2} = a^3e^{-c^2 / \alpha^2}.
    \] We must now normalise the distributions. We demand \[
        \int_{-\infty}^{+\infty} f(t)\:dt = \int_{-\infty}^{+\infty} ae^{-t^2 /
        \alpha^2}\:dt = \sqrt{\pi}a\alpha = 1.
    \] We deduce that $a$ and $\alpha$ must be functions of $T$ and $m$.
    Now, we can write \[
        dn = \frac{n}{\alpha^3\pi^{3 / 2}} e^{-c^2 / \alpha^2} \:d\gamma.
    \] Integrating over $\theta$ and $\phi$, we have \[
        dn_c = \frac{4n}{\alpha^3\pi^{1 /2}} c^2 e^{-c^2 / \alpha^2} \:dc
    \] Now, we can calculate the moments \[
        \E{c} = \frac{1}{n}\int_0^\infty c\:dn_c = \frac{2\alpha}{\sqrt{\pi}}, \qquad
        \E{c^2} = \frac{1}{n}\int_0^\infty c^2\:dn_c = \frac{3}{2}\alpha^2.
    \] The most probable velocity $c_{mp}$ is such that the derivative of the
    probability density vanishes. We see that $c_{mp} = \alpha$.
    The ratio of these velocities is given by \[
        c_{avg} \,:\, c_{rms} \,:\, c_{mp} \,=\, 
            \frac{2}{\sqrt{\pi}} \,:\, \sqrt{\frac{3}{2}} \,:\, 1.
    \] Recall that we have already calculated $\E{c^2} = 3 k_B T /m$. Thus, \[
        \alpha = \sqrt{\frac{2k_B T}{m}}.
    \]
    \begin{theorem}[Maxwell-Boltzmann distribution]
        The velocity distribution of an ideal gas is given by \[
            dn_c = 4\pi n\left( \frac{m}{2\pi k_B T} \right)^{3 /2} c^2\, e^{-mc^2 /
            2k_B T} \:dc.
        \] 
    \end{theorem}
    The distribution of kinetic energies $\epsilon$ can be obtained by using $E =
    mc^2 / 2$ and $\epsilon = E / k_B T$, so \[
        dn_\epsilon = \frac{2n}{\sqrt{\pi}}\sqrt{\epsilon}\,
        e^{-\epsilon}\:dn_\epsilon.
    \] 

    \subsection{Degrees of freedom}
    \begin{definition}
        The number of independent coordinates which completely describe the state of
        a collection of particles is called the number of degrees of freedom of the
        collection.
    \end{definition}

    Consider a point mass travelling in 3D space. Its position can be pinned down by
    3 coordinates, which means that it has 3 degrees of freedom. In an ideal gas
    with $N$ particles, there is no correlation between the motion of each particle.
    Thus, degrees of freedom of each particle add up, giving $3N$ degrees of freedom
    of the gas. On the other hand, if the motion of the particles is constrained,
    this reduces the degrees of freedom by the number of these constraints.

    For example, consider a rigid body made of $N \geq 3$ point masses, $m_1, m_2,
    \dots, m_N$. The first mass has 3 degrees of freedom, the second has 2 and the
    third has 1. Once these are fixed, the positions of the remaining particles are
    forced, so the system has exactly 6 degrees of freedom. Another way to see this
    is that the position of the rigid body is defined by the position of its centre
    of mass and its orientation in space, which gives 3 + 3 degrees of freedom.
    
    Another perspective is to look at the number of free variables in the kinetic
    energy of the system. A point mass in 3D has 3 degrees of freedom because its
    kinetic energy is given by \[
        \mathscr{T} = \frac{1}{2}m(\dot{x}^2 + \dot{y}^2 + \dot{z}^2).
    \] For a rigid body, its kinetic energy is given by \[
        \mathscr{T} = \frac{p^2}{2m} + \frac{1}{2}I\omega^2,
    \] where the translational and rotational kinetic energies each contribute 3
    degrees of freedom.

    Consider a system with generalized coordinates $q_1, q_2, \dots, q_n$. This
    system has $n$ degrees of freedom, including translational and rotational
    degrees. We can also write generalized velocities $\dot{q_1}, \dot{q_2}, \dots,
    \dot{q_n}$. The generalized momenta can be defined as \[
        p_i = \pp{E}{\dot{q_i}},
    \] where $E = \mathscr{T} + \mathscr{V}$ is the total energy of the system. Note
    that the potential $\mathscr{V}(q_i)$ can only be a function of the coordinates
    $q_i$, while the kinetic energy $\mathscr{T}$ must be a homogeneous quadratic
    function of $p_i$. Maxwell showed that we can write the following distribution
    for the velocities, \[
        F(\dot{q_i})\:d\dot{q_1}\dots\:d\dot{q_n} = c e^{-\mathscr{T} /k_B T}
        \:d\dot{q_1}\dots\:d\dot{q_n}.
    \] Here, $F(\dot{q_i})d\gamma$ is the probability of finding the system in the
    velocity ranges $\dot{q_i} \to \dot{q_i} + d\dot{q_i}$.
    Boltzmann showed that we can generalize further with  \[
        F(q_i, p_i)\:dq_1\:dp_1\dots\:dq_n\:dp_n = c e^{-E /k_B T}
        \:dq_1\:dp_1 \dots \:dq_n\:dp_n.
    \] Here, we talk about position as well as momenta.

    \begin{theorem}[Equipartition of energy]
        If a system attains equilibrium at a temperature $T$, then the total kinetic
        energy $\mathscr{T}$ gets equally distributed between the degrees of
        freedom, with each degree of freedom getting $k_B T / 2$.
    \end{theorem}   
    Recall that in general, the kinetic energy can be written as \[
        \mathscr{T} = \sum c_{ij}p_i p_j.
    \] We can perform a suitable coordinate transformation to get rid of cross
    terms, thus obtaining the co-momenta $\xi_i$. Now, \[
        \mathscr{T} = \sum \beta_i \xi_i^2, \qquad 
        E = E' + \beta_j\xi_j^2.
    \] Thus, the Boltzmann distribution can be written as \[
        \int ce^{-(E' + \beta_j\xi_j^2) / k_BT} \:d\gamma' = 1,
    \] integrating over all possible $q_i$ and $\xi_i$. This gives us the
    normalisation factor $c$. The average kinetic energy associated with $q_j,
    \xi_j$ is thus the expectation value \[
        \int \beta_i\xi_j^2 \cdot ce^{-(E' + \beta_j\xi_j^2) / k_BT} \:d\gamma' =
        \frac{\displaystyle\int \beta_j \xi_j^2 e^{-\beta_j\xi_j^2 / k_B T}
        \:d\xi_j}{\displaystyle\int e^{-\beta_j\xi_j^2 / k_BT}\:d\xi_j} =
        \frac{1}{2}k_BT.
    \] 

    \subsection{Transport phenomena}
    We make a distinction between \textit{random motion} and \textit{mass motion}.
    When a gas is at equilibrium, quantities such as temperature, density, pressure,
    etc.\ are uniform over the entire volume. However, a gas may not be in
    equilibrium, in which case there will be a tendency to restore equilibrium by
    `movement' of the quantities which are not uniform. If the temperature in a gas
    is not uniform, we have transport of heat; if the density is not uniform, we
    have a bulk transport of mass. These are diffusion phenomena; while the gas
    particles are always in random motion, there is an overall `flow' which is
    directed from a region of higher concentration (of heat, mass, etc) to lower
    concentration.

    \subsubsection{Viscosity}
    Consider the presence of mass motion (with a certain flow velocity) in addition
    to thermal motion. Also assume that the flow velocity increases uniformly in a
    direction perpendicular to the motion. Let the flow velocity be $u_0$ in the
    positive $y$ direction. Then, at a volume $dV$ located at $(r, \theta, \phi)$,
    we have a flow velocity \[
        u_0 + r\cos\theta\,\pp{u}{z}.
    \] The term $\partial u / \partial z$ is the velocity gradient.
    We repeat the procedure of choosing a small area $\Delta S$ on the $xy$ plane to
    get the number of molecules colliding as \[
        dN = \frac{\cos\theta \Delta S}{4\pi r^2}\cdot \frac{\E{c}\Delta
        t}{\lambda}\cdot e^{-r / \lambda}\,n\:dV.
    \] We have already averaged over the speeds $c$. Now, if all these molecules
    retain their flow velocity from $dV$ after collision, there is a transfer of
    momentum from that $z$ layer to the $xy$ plane, given by \[
        m\left(u_0 + r\cos\theta\,\pp{u}{z}\right)\:dN.
    \] There is a symmetric layer on the other side of the plane which transfers a
    momentum \[
        m\left(u_0 - r\cos\theta\,\pp{u}{z}\right)\:dN
    \] in the opposite direction. Thus, the net momentum transfer is \[
        2mr\cos\theta\,\pp{u}{z}\:dN.
    \] Integrating over the upper half volume, we get a momentum transfer of \[
        \Delta p = \frac{1}{3}mn\E{c}\lambda \pp{u}{z}\Delta S\:\Delta t.
    \] Recall that when a shear force is applied on a layer, we have \[
        F = \eta \pp{u}{z}\Delta S,
    \] where $\eta$ is the coefficient of viscosity. Comparing this with $\Delta p /
    \Delta t$, we get \[
        \eta = \frac{1}{3}mn\E{c}\lambda = \frac{m\E{c}}{3\sqrt{2}\pi\sigma^2}.
    \] Combining the temperature dependencies of $\E{c}$ and $\sigma^2$, we have \[
        \eta \propto \frac{\sqrt{T}}{1 + b/ T}, \qquad \eta =
        \eta_0\sqrt{\frac{T}{T_0}} \cdot\frac{1 + b / T_0}{1 + b / T}.
    \] As a first order approximation, $\eta \propto \sqrt{T}$ for large $T$.

    \subsubsection{Conductivity}
    We proceed exactly as before, except now we have a temperature gradient
    $\partial T / \partial z$ rather than a velocity gradient. Let the heat capacity
    of a molecule be given by $mc_v$ -- this replaces the momentum. The heat carried
    per molecule is thus given as \[
        mc_v\left(T_0 + r\cos\theta\,\pp{T}{z}\right)\:dN.
    \] Hence, applying symmetry again, the total heat transmitted through $\Delta S$
    is given as \[
        2mc_v\cos\theta\,\pp{T}{z}\:dN.
    \] Integrating again, \[
        \Delta Q = \frac{1}{3}mnc_v\E{c}\lambda \pp{T}{z}\Delta S\:\Delta t.
    \] Thermal conductivity is defined as $\kappa$ where \[
        \frac{\Delta Q}{\Delta t} = \kappa \pp{T}{z}\Delta S.
    \] Comparing, \[
        \kappa = \frac{1}{3}mn\E{c}\lambda c_v = \eta c_v.
    \] In practice however, we observe $\kappa / \eta c_v > 1$, often as high as
    $2.5$ for monoatomic gases, $1.9$ for diatomic and $1.75$ for triatomic gases.
    This discrepancy arises because of the assumption that all molecules move with
    speed $\E{c}$, while in reality they follow a distribution. Faster molecules
    will collide more often, and carry a larger kinetic energy, which biases the
    energy to a higher value. Another factor is that $\lambda_c$ has a dependence on
    $c$, as shown by Tait. \[
        \lambda_c = \frac{c^2}{\alpha^2\sqrt{\pi}n\sigma^2\psi(c / \alpha)},
    \] where $\psi$ is a function of $c$.

    One approach is to define $\epsilon = \kappa/\eta c_v$, and show that
    $\epsilon = 5 / 2$ for monoatomic gases using a statistical mechanics argument
    taking into account intermolecular forces (Chapman and Enskog). We can also
    split $\epsilon = \epsilon_t + \epsilon_r$, where $\epsilon_t$ is the
    contribution purely from translational degrees of freedom. This gives \[
        \kappa = \eta(\epsilon_tc_t + \epsilon_rc_r), \qquad 
        \epsilon = \frac{\epsilon_tc_t + \epsilon_rc_r}{c_t + c_r}.
    \] For monoatomic gases, $c_r = 0$ and $\epsilon = 5 /2$. For polyatomic
    molecules, we have $c_r$ contributing due to rotational and vibrational degrees
    of freedom. There are $3$ translational degrees of freedom per molecule; let the
    remaining be $\beta$ ($2$ for diatomic, $3$ for triatomic). Now, \[
        c_t = \frac{1}{J_m}\dd{}{T}\left(\frac{3}{2}k_BT\right) = \frac{3k_B}{2J_m}.
    \] Similarly, \[
        c_r = \frac{\beta k_B}{2J_m}.
    \] Setting $\epsilon_t = 5 / 2$, $\epsilon_r = 1$, we get \[
        \epsilon = \frac{15 + 2\beta}{6 + 2\beta}.
    \] We wish to write this in terms of $\gamma = c_p / c_v$. Now, $c_p = c_v + k_B
    / J_m$. This gives \[
        \frac{\kappa}{\eta c_v} = \epsilon = \frac{9\gamma - 5}{4}.
    \] 

    \subsubsection{Diffusivity}
    Again, consider a density gradient $\partial n / \partial z$. Now, \[
        dN = \frac{\cos\theta \Delta S}{4\pi r^2}\cdot \frac{\E{c}\Delta
        t}{\lambda}\cdot e^{-r / \lambda}\,\left(n_0 +
        r\cos\theta\,\pp{n}{z}\right)\:dV,
    \] above the $xy$ plane. Repeating the procedure with the mirror half and
    integrating, we get the flow of particles through our area $\Delta S$ as \[
        \Delta N = \frac{1}{3}\E{c}\lambda \pp{n}{z}\Delta S \Delta t.
    \] From the definition of diffusivity, \[
        \frac{\Delta N}{\Delta t} = D \pp{n}{z}\Delta S.
    \] Comparing, \[
        D = \frac{1}{3}\E{c}\lambda = \frac{\eta}{\rho}.
    \] 

    \subsubsection{Interdiffusivity}
    Instead of having just one gas with a density gradient, consider two gases with
    densities $n_a$ and $n_b$, diffusing in the same container in opposite directions.
    Note that the mean free paths of the gases are different, $\lambda_a$ and
    $\lambda_b$. Using the fact that $n_a + n_b = n$ remains constant, \[
        \pp{n_a}{z} = -\pp{n_b}{z} = \pp{n'}{z}.
    \] Consider an area $\Delta S$ perpendicular to the $z$ axis. The number of
    molecules of each type of gas passing through this area is given as \[
        \Delta N_a = \frac{1}{3}\E{c}_a\lambda_a \pp{n_a}{z}\Delta S \Delta t, \qquad
        \Delta N_b = \frac{1}{3}\E{c}_b\lambda_b \pp{n_a}{z}\Delta S \Delta t.
    \] The total is \[
        \Delta N = \underbrace{\frac{1}{3}\left(\E{c}_a\lambda_a -
        \E{c}_b\lambda_b\right)}_{D'}\pp{n'}{z}\Delta S \Delta t.
    \] Now if $D' \neq 0$, then there is an overall flow of gas molecules in a
    particular direction. However, we want the total density and pressure to remain
    the same everywhere. In order to stop this from happening, there must be a mass
    motion of molecules in the opposite direction, say with velocity $v$. The number
    of such molecules moving through $\Delta S$ is $nv\Delta S \Delta t$. Combining
    this with $\Delta N$ and setting the net movement to zero, \[
        v = -\frac{D'}{n}\pp{n'}{z}.
    \] The flow of the first type of molecules is thus $n_av\Delta S\Delta t + 
    \Delta N_a$. We define the interdiffusivity of one type of gas into the other as \[
        D_{ab} = \frac{1}{3} \frac{n_b\E{c}_a\lambda_a + n_a\E{c}_b\lambda_b}{n_a +
        n_b}.
    \] This proceeds at a rate \[
        \frac{\Delta N_{ab}}{\Delta t} = D_{ab}\pp{n'}{z}\Delta S.
    \] This is called Meyer's Law. Note that $n_a$ and $n_b$ vary spatially, hence
    so does $D_{ab}$. Also, when $n_a \gg n_b$, we recover the diffusivity of a
    single gas, \[
        D_{ab} \to \frac{1}{3}\E{c}_b\lambda_b.
    \]

    In the special case where $D' = 0$, we observe $v = 0$ and $D_{ab} =
    \E{c}\lambda$ assuming identical $\E{c}$ and $\lambda$. Now, $D_{ab}$ becomes
    spatially independent.

    \subsection{Brownian motion}
    Consider a homogeneous, isotropic system with really small molecules. These
    molecules are in constant random motion, due to collisions. They are
    thermalised, each with energy $\approx 3k_B T /2$. At any moment, a given
    molecule is bombarded from all sides by different molecules. These forces do not
    necessarily cancel, giving rise to a fluctuation force, thus driving motion.  In
    a typical system like liquid water, the molecules are far too small to directly
    observe this motion. Instead, we place some test particles; not so small that
    their motion is invisible, not so large that their motion cannot be affected by
    the fluctuation forces. Robert Brown performed such experiments with pollen
    grains (on the order of $10^4$ times larger than water molecules), confirming
    that their motion is random and constant. Another example is that of smoke
    particles in the atmosphere. One important property of Brownian particles is
    that their motion is uncorrelated. This means that eddy currents, convection, 
    streamline mass motion, etc.\ are excluded. Any mechanical motion of the
    container has no effect. Naturally, the smaller the particles, the greater is
    the motion; same for lower viscosities. Higher temperatures give a greater
    average motion -- the velocities during the mean path are increased. Thus,
    Brownian particles can be treated as ideal gas particles in thermal equilibrium
    with the surrounding fluid medium.

\end{document}
% vim: set tabstop=4 shiftwidth=4 softtabstop=4:
