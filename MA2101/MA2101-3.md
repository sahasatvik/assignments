# Analysis I

$
\newcommand\R{\mathbb{R}}
\newcommand\Q{\mathbb{Q}}
\newcommand\Z{\mathbb{Z}}
\newcommand\N{\mathbb{N}}
\newcommand\ve[1]{\boldsymbol{#1}}
\newcommand\norm[1]{\left\Vert #1 \right\Vert}
\def\u{\ve{u}}
\def\v{\ve{v}}
\def\w{\ve{w}}
\def\C{\mathcal{C}}
\def\diam{\operatorname{diam}}
$

## Sequences
A *sequence* is a function whose domain is the set of natural numbers.
The values of the function are called terms of the sequence.
$$ \alpha\colon\N \to S,\quad n \mapsto \alpha_n.$$
We denote $\alpha_n = \alpha(n)$, and denote the whole sequence as $\{\alpha_n\}$ or $(\alpha_n)_{n \in \N}$.

If the image of $\alpha$ is bounded below or above, we say that the sequence is *bounded* below or above. If the sequence is bounded both below and above, then we say that the sequence is *bounded*.

A sequence $\{\alpha_n\}$ in a metric space $(M, d)$ is said to *converge* to a point $p \in M$, written $\alpha_n \to p$, if for every $r > 0$, there exists $N \in \N$ such that for all $n \geq N$, we have $\alpha_n \in B_r(p)$.

Note that a sequence converges to a point $p$ only if $p$ is a limit point of the set $\{\alpha_1, \alpha_2, \dots\}$. We write
$$ \lim_{n \to \infty} \alpha_n = p. $$

Also note that if $\alpha_n \to p$ in $M$, then the sequence $d(\alpha_n, p) \to 0$ in $\R$.

A *divergent* sequence is one which does not converge.

If $\alpha_n \to a$ and $\alpha_n \to b$ in a metric space $(M, d)$, then $a = b$.

If $\alpha_n$ converges, then $\alpha_n$ is bounded.

If $\alpha_n \to a$ and $\beta_n \to b$, then $\alpha_n + \beta_n \to a + b$ and $\alpha_n\beta_n \to ab$. Additionally, if $\beta_n \neq 0$ and $b \neq 0$, then $\alpha_n/\beta_n \to a /b$.

If $\ell$ is a limit point of $S$, then there is a sequence $\{s_n\}$ in $S$ such that $s_n \to \ell$.

#### Subsequences

Given a sequence $\{\alpha_n\}$, consider an increasing sequence $n_k$ of positive integers. Then, the sequence $\{\alpha_{n_k}\}$ is called a *subsequence* of $\{\alpha_n\}$. If $\{\alpha_{n_k}\}$ converges, its limit is called the *sub-sequential limit* of $\{\alpha_n\}$.

Let $(M, d)$ be a compact metric space and let $\{\alpha_n\}$ be a sequence in $M$. Then, some subsequence of $\{\alpha_n\}$ converges to a point of $M$.

Every bounded sequence in $\R^n$ has a convergent subsequence.

Let $(M, d)$ be a metric space and let $\{\alpha_n\}$ be a convergent sequence in $M$. Then for every $\epsilon > 0$, there exists $N \in \N$ such that $d(\alpha_m, \alpha_n) < \epsilon$ if $\min(m, n) \geq N$.

### Cauchy sequences
A sequence $\{\alpha_n\}$ in a metric space $(M, d)$ is called a *Cauchy sequence* if for every $\epsilon > 0$, there is an integer $N \in \N$ such that $d(\alpha_m, \alpha_n) < \epsilon$ if $\min(m, n) \geq N$.

If a subsequence $\{\alpha_{n_k}\}$ of a Cauchy sequence $\{\alpha_n\}$ converges to a limit point $\ell$, then the entire sequence $\{\alpha_n\}$ converges to $\ell$.

A metric space $(M, d)$ is called *Cauchy complete* if every Cauchy sequence in $M$ converges in $M$.

Every compact subset of a metric space is Cauchy complete.

All Euclidean spaces are Cauchy complete.

#### Cauchy criterion
A sequence in a Euclidean space $\R^n$ converges *iff* it is Cauchy.

### Constructing the real numbers
Let $\C$ denote the set of all rational Cauchy sequences. Let $\{\alpha_n\}, \{\beta_n\} \in \C$. We say that the sequences $\{\alpha_n\} \sim \{\beta_n\}$ if $|\alpha_n - \beta_n| \to 0$. It is easily verified that $\sim$ is an equivalence relation.

We define $\R$ as the quotient space of this relation, *i.e.*
$$ \R = \C /\sim. $$

The rationals are embedded in the usual way, and addition and multiplication are defined termwise.

The order on $\R$ is defined as follows: $\{\alpha_n\} > \{\beta_n\}$ if there exists $N$ such that $\alpha_n > \beta_n$ for all $n \geq N$, and $|\alpha_n - \beta_n| \not\to 0$.

#### Completeness of the reals
Let $S$ be a nonempty subset of $\Q$ and let $u_1\in \Q$ be an upper bound of $S$. Let $s\in S$ and let $\ell_1 \in \Q$ be such that $\ell_1 < s$. We define two rational Cauchy sequences $\{u_n\}$ and $\{\ell_n\}$ as follows
$$ \begin{align}
u_{n + 1} &= \begin{cases}
	(u_n + \ell_n)/2, &\text{if this is an upper bound of }S, \\
	u_n, &\text{otherwise}
\end{cases},\\
\ell_{n + 1} &= \begin{cases}
	(u_n + \ell_n)/2, &\text{if this is not an upper bound of }S, \\
	\ell_n, &\text{otherwise}
\end{cases}.
\end{align}$$
It follows that all $u_n$ are upper bounds of $S$, and none of $\ell_n$ are.

Suppose $\{u_n\} < \{s_n\}$ for some $\{s_n\} \in S$. This would mean that for some sufficiently large $n_0$, $u_{n_0} < s_{n_0}$, which is a contradiction. Thus, $\{u_n\}$ is an upper bound of $S$.

Also note that
$$ u_n - \ell_n = \frac{u_1 - \ell_1}{2^{n - 1}}, $$
so $\{u_n\} \sim \{\ell_n\}$. Thus, $\{u_n\} = \{\ell_n\}$ in $\R$.

Let $\{a_n\} \in \R$ be an upper bound of $S$ such that $\{a_n\} < \{u_n\}$. It follows that $\{a_n\} < \{\ell_n\}$ in $\R$. This implies that there exists $\epsilon > 0$ and $N_1 \in \N$ such that 
$$ \ell_n - a_n > \epsilon, $$
for all $n \geq N_1$. Since $\{\ell_n\}$ is a Cauchy sequence, there exists $N_2 \in \N$ such that for all $m, n \geq N_2$, $|\ell_m - \ell_n| < \epsilon/2$. Thus, setting $N = \max(N_1, N_2)$, we see that for all $n \geq N$, we have
$$ \ell_n - \ell_N < \epsilon/2. $$
Therefore,
$$\ell_n - a_n \geq (\ell_N - \ell_n) - (\ell_n - a_n) > \epsilon/2, $$
for all $n \geq N$. This means that $\{a_n\}$ is greater than the constant sequence $\{\ell_N\}$. However, $\ell_N$ was not an upper bound of $S$, so neither can $\{a_n\}$ be an upper bound of $S$, which is a contradiction. Thus, $\{u_n\}$ is the least upper bound of $S$.
This shows that $\R$ has the least upper bound property, *i.e.* $\R$ is complete.

### Sequentially compact spaces
A subset $S$ of a metric space $(M, d)$ is called *sequentially compact* if every sequence of points in $S$ has a convergent subsequence which converges to a point in $S$.

Note that the Heine-Borel theorem guarantees that in Euclidean spaces, compactness and sequential compactness are equivalent. This is indeed true for all metric spaces.

Let $S \subseteq M$ be nonempty, and let $D = \{d(x, y): x, y \in S\}$.
We define the dimeter of $S$ as $\sup{D}$.

Let $\{\alpha_n\}$ be a sequence in a metric space $(M, d)$ and for $N \in \N$, let $S_N = \{\alpha_n: n \geq N\}$. Then, $\{\alpha_n\}$ is a Cauchy sequence *iff* 
$$ \lim_{N \to \infty} \diam{S_N} = 0. $$

Let $S$ be a subset of a metric space $(M, d)$. Then, $\diam{\overline{S}} = \diam{S}$.

If $K_n$ is a nested sequence of compact sets in $M$ such that $\lim_{n \to \infty} \diam{K_n} = 0$, then there exists a point $p \in M$ such that
$$ \bigcap_{n \in \N} K_n = \{p\}. $$

#### Monotone Convergence theorem

Every nondecreasing or nonincreasing sequence sequence is called monotone.
Every bounded monotonic sequence converges in $\R$.

#### Subsequential limits

Let $S$ be the set of all subsequential limits of the sequence $\{\alpha_n\}$ in a metric space $(M, d)$. Then, $S$ is closed.

Let $\{\alpha_n\}$ and $\{\beta_n\}$ be real sequences such that for all $M \in \R$, there exists $N \in \N$ such that for every $n \geq N$, $\alpha_n \geq M$ and $\beta_n \leq M$. We say that $\{\alpha_n\}$ diverges to $\infty$ and $\{\beta_n\}$ diverges to $-\infty$. We write
$$ \alpha_n \to \infty, \qquad \beta_n \to -\infty. $$

Again, let $S$ denote the set of all subsequential limit of $\{\alpha_n\}$. If any subsequence of diverges to $\pm \infty$, we let $\pm\infty \in S$. Thus, $s^* = \sup{S}$ and $s_* = \inf{S}$ exist in the extended real number system. These are called the *upper* and *lower limits* of the sequence $\{\alpha_n\}$. These are denoted as
$$ \limsup_{n \to \infty} \alpha_n = s^*, \qquad
\liminf_{n \to \infty} \alpha_n = s_*. $$

In general, $\alpha_n \to \ell$ *iff* $s^* = s_* = \ell$.

If $s^* \neq s_*$, we say that the sequence $\{\alpha_n\}$ *oscillates*. The *oscillation* $\omega(\{\alpha_n\})$ of the sequence $\{\alpha_n\}$ is defined as $s^* - s_*$ if both are finite, else $\infty$.

With $S$, $s^*$ and $s_*$ defined as before, then $s^* \in S$. If $x > s^*$, then there exists an integer $N$ such that for all $n \geq N$, we have $\alpha_n < x$. There is no other element of the extended reals which satisfies both of these properties.

### Series
Given a sequence $\{\alpha_n\}$ in $\R$, we define the $k^\text{th}$-partial sum as $s_k = \sum_{n = 1}^k \alpha_n$.

If the sequence of the partial sums $\{s_k\}$ converges, *i.e.* $s_k \to s$, we say that the series $\alpha_1 + \alpha_2 + \dots $ converges to $s$. Otherwise, we say that it diverges.

The Cauchy criterion for the sequence $\{s_k\}$ implies that the series $\sum_{n = 1}^\infty \alpha_n$ converges *iff* for every $\epsilon > 0$, there exists an integer $N$ such that for all $n > m \geq N$, we have
$$ \left|\sum_{j = m + 1}^n \alpha_j \right| < \epsilon. $$

In particular, if the series $\sum_{n = 1}^\infty \alpha_n$ converges, then $\alpha_n \to 0$.

The Monotone Convergence theorem implies that a series of nonnegative reals converges *iff* its partial sums forms a bounded sequence.

> Consider the geometric series $\sum_{n = 1}^\infty a^n$.
Note that the partial sums are 
$$s_k = \sum_{n = 1}^k a^n = \frac{1 - a^{k + 1}}{1 - a}.$$
When $a \neq 0$, $-1 < a < 1$, the series converges to $\ell = 1 /(1 - a)$. Note that
$$ |s_k - \ell| = |\ell| |a^{k + 1}|. $$
For $a > 1$ and $a < 1$, note that $a^n \not\to 0$, hence the series diverges.

The *comparison test* states that for two real sequences $\{\alpha_n\}$ and $\{\beta_n\}$, suppose that $|\alpha_n| < \beta_n$ for all $n \geq N \in \N$. Then, if the series $\sum \beta_n$ converges, so does $\sum \alpha_n$.
Also, if $0 \leq \alpha_n < \beta_n$ for all $n \geq N \in \N$ and $\sum \alpha_n$ diverges, so does $\sum \beta_n$.

The *Cauchy condensation test* states that if $\{\alpha_n\}$ is a nonincreasing sequence of non-negative reals, the series $\sum \alpha_n$ converges *iff* the series $\sum 2^n\alpha_{2^n}$ converges.

> The series $\sum 1/n^j$ converges *iff* $j > 1$. This can be shown using the Cauchy condensation test, whereby the given series converges *iff* $\sum 2^n /(2^n)^j = \sum 2^{(1 - j)n}$ converges. This is a geometric series, which converges *iff* $2^{1 - j} < 1$, *i.e.* $j > 1$. Note that we can only use the Cauchy condensation test when $j > 0$, but the series diverges trivially when $j \leq 0$ since the terms do not go to zero.

The *root test* states that for a real sequence $\{\alpha_n\}$, the series $\sum \alpha_n$ converges if $\limsup_{n \to \infty} |\alpha_n|^{1/n} < 1$ and diverges if $\limsup_{n \to \infty} |\alpha_n|^{1/n} > 1$. No conclusion can be made if the limit is exactly $1$.

The D'Alembert *ratio test* states that for a real sequence $\{\alpha_n\}$ such that $\alpha_n \neq 0$ for $n \geq N$, the series converges if $\limsup_{ n\to \infty} |\alpha_{n + 1} / \alpha_n| < 1$ and diverges if $\limsup_{ n\to \infty} |\alpha_{n + 1} / \alpha_n| > 1$. No conclusion can be made if the limit is exactly $1$.

For a real sequence $\{\alpha_n\}_{n = 0}^\infty$, the series
$$ \sum_{n = 0}^\infty \alpha_n x^n$$
is called the *power series* of $\{\alpha_n\}$.

Suppose $a = \limsup_{n \to \infty} |\alpha_n|^{1/n}$ for such a sequence. Let $R = 0$ if $a = \infty$, $R = \infty$ if $a = 0$, and $R = 1/a$ otherwise. The *Cauchy Hadamard theorem* states that the power series $\sum \alpha_nx^n$ converges if $|x| < R$ and diverges if $|x| > R$. The quantity $R$ is called the *radius of convergence* of the power series.

> The exponential function is defined as
$$ \exp(x) = \sum_{n = 0}^\infty \frac{x^n}{n!}. $$
Note that the ratio test gives that as $n \to \infty$,
$$ \left|\frac{x^{n + 1}}{(n + 1)!}\cdot\frac{n!}{x^n}\right| = \left|\frac{x}{n + 1}\right| \to 0. $$
Thus, the series converges everywhere, *i.e.* has a radius of convergence $R = \infty$.

> The number $e = \exp(0)$ is called *Euler's number*.

#### Absolute convergence
Let $\{\alpha_n\}$ be a real sequence. We say that the series $\sum \alpha_n$ *converges absolutely* if the series $\sum |\alpha_n|$ converges.

If a real series converges absolutely, it also converges.

A series $\sum \alpha_n$ *converges conditionally* if it converges, but the series $\sum |\alpha_n|$ diverges.

*Abel's Lemma* states that given two sequences $\{\alpha_n\}_{n = 0}^\infty$ and $\{\beta_n\}_{n = 0}^\infty$, define the $k^\text{th}$ partial sums
$$ s_k = \sum_{n = 0}^k \alpha_n. $$
Also define $s_k = 0$ if $k \neq \N$. Then, for $0 \leq m \leq n$, we have
$$ \sum_{j = m}^n \alpha_j\beta_j = \sum_{j = m}^{n - 1} s_j(\beta_j - \beta_{j + 1}) + s_n\beta_n - s_{m - 1}\beta_m. $$

Suppose that $\{s_k\}$ is bounded, the sequence $\{\beta_n\}$ is nonincreasing, and $\beta_n \to 0$. Then, $\sum \alpha_j\beta_j$ converges.

Let $\{\alpha_n\}$ be a nonincreasing sequence where $\alpha_n \to 0$. Let the radius of convergence of the power series $\sum\alpha_nx^n$ be $1$. Then, this power series also converges at $x = -1$.

> We see that the alternating harmonic series $\sum (-1)^n /n$ converges.

Let $\{\alpha_n\}$ be a real sequence such that the sequence $\{|\alpha_n|\}$ is nonincreasing, $a_{2m - 1} > 0$ and $a_{2m} < 0$ for all $m \in \N$, and $a_n \to 0$, then the series $\sum \alpha_n$ converges.

Let $f\colon\N\to\N$ be a bijection. We say that the series $\sum \alpha_{f(n)}$ is a rearrangement of the series $\sum \alpha_n$.

Let $\sum \alpha_n$ be an absolutely convergent series, and let $f\colon\N\to\N$ be a bijection. Then, the rearranged series $\sum\alpha_{f(n)}$ is also absolutely convergent, and converges to the same value as the original series.

Let $\sum \alpha_n$ be conditionally convergent. Then for each pair of $a$ and $b$ in the extended reals with $a \leq b$, the given series has a rearrangement $\sum \alpha_{f(n)}$ with partial sums $s_k'$ such that 
$\liminf_{k \to \infty} s_k' = a$, and $\limsup_{k \to \infty} s_k' = b$.

### Continuity
Let $(M, d)$ and $(M', d')$ be metric spaces. Let $S \subseteq M$, $S' \subseteq M'$ and let there be a function $f\colon S \to S'$. Let $a$ be a limit point of $S$. For $b \in S'$, we write $f(x) \to b$ as $x \to a$ or
$\lim_{x \to a}f(x) = b$ if the preimage of every open ball around $b$ contains an open ball around $a$.

> Note that $b$ may not be an element of $S'$. Neither does $a$ have to be an element of $S$.

Equivalently, we say that $\lim_{x \to a}f(x) = b$ *iff* for every sequence $\{\alpha_n\}$ in $S$ such that $\lim_{n \to \infty} \alpha_n = a$ and $\alpha_n \neq a$ for all but finitely many $n$, we have $\lim_{n \to \infty} f(\alpha_n) = b$.

The function $f\colon S \to S'$ is said to be continuous at $a \in S$ if for every open set $\mathcal{O}' \subseteq S'$ containing $f(a)$, there exists an open set $\mathcal{O} \subseteq S$ containing $a$ such that $\mathcal{O} \subseteq f^{-1}(\mathcal{O}')$.

If $f$ is continuous at every point of $S$, we say that $f$ is continuous on $S$.

Thus, for $f\colon M \to M'$, $f$ is continuous on $M$ *iff* the inverse images of all open sets are open.

This immediately means that $f$ is continuous *iff* the inverse images of all closed sets are closed.

Let $a, b \in \R$ with $a < b$. Let $f\colon (a, b) \to M$ be a function. For $x \in [a, b)$, we write $f(x+)  = \alpha$ if $f(\alpha_n) \to \alpha$ for all sequences $\{\alpha_n\}$ in $(x, b)$ such that $\alpha_n \to x$.
This is called the *right hand limit*.

For $f\colon (a, b) \to M$ suppose $f$ is discontinuous at $x$. If both $f(x+)$ and $f(x-)$ exist, then $f$ has a discontinuity of the first kind, a simple discontinuity at $x$. Otherwise, we say that $f$ has a discontinuity of the second kind at $x$.

#### Connectedness

A *connected* space is one which cannot be expressed as the union of two or more disjoint, non-empty open sets. More precisely, a *disconnected* space is the union of two disjoint non-empty open sets.

The continuous image of a connected set is connected.

Every non-empty interval in $\R$ is connected. In addition, every connected subset of $\R$ is an interval.

Let $a, b \in \R$ with $a < b$ and let $f\colon [a, b] \to \R$ be continuous. Let $\alpha = \min(f(a), f(b))$ and $\beta = \min(f(a), f(b))$. Then, for every $y \in [\alpha, \beta]$, there exists $x \in [a, b]$ such that $f(x) = y$.