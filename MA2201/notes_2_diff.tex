\documentclass[11pt]{article}

\usepackage[T1]{fontenc}
\usepackage{geometry}
\usepackage{amsmath, amssymb, amsthm}
\usepackage[scr]{rsfso}
\usepackage[%
    hidealllines=true,%
    innerbottommargin=15,%
    nobreak=true,%
]{mdframed}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{fancyhdr}
\usepackage{lipsum}
\usepackage{hyperref}

\geometry{a4paper, margin=1in, headheight=14pt}

\pagestyle{fancy}
\fancyhf{}
\renewcommand\headrulewidth{0.4pt}
\fancyhead[L]{\scshape MA2201: Analysis II}
\fancyhead[R]{\scshape Differentiation}
\rfoot{\footnotesize\it Updated on \today}
\cfoot{\thepage}

\def\C{\mathbb{C}}
\def\R{\mathbb{R}}
\def\Q{\mathbb{Q}}
\def\Z{\mathbb{Z}}
\def\N{\mathbb{N}}
\newcommand\ddx[1]{\frac{d #1}{d x}}
\newcommand\ddt[1]{\frac{d #1}{d t}}
\newcommand\dd[3][]{\frac{d^{#1}{#2}}{d {#3}^{#1}}}
\newcommand\ppx[1]{\frac{\partial #1}{\partial x}}
\newcommand\ppt[1]{\frac{\partial #1}{\partial t}}
\newcommand\pp[3][]{\frac{\partial^{#1}{#2}}{\partial {#3}^{#1}}}
\newcommand\norm[1]{\left\lVert#1\right\rVert}

\newcounter{module}
\setcounter{module}{2}

\newmdtheoremenv[%
    backgroundcolor=blue!10!white,%
]{theorem}{Theorem}[module]
\newmdtheoremenv[%
    backgroundcolor=violet!10!white,%
]{corollary}{Corollary}[theorem]
\newmdtheoremenv[%
    backgroundcolor=teal!10!white,%
]{lemma}[theorem]{Lemma}

\theoremstyle{definition}
\newmdtheoremenv[%
    backgroundcolor=green!10!white,%
]{definition}{Definition}[module]
\newmdtheoremenv[%
    backgroundcolor=red!10!white,%
]{exercise}{Exercise}[module]

\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\newtheorem*{example}{Example}
\newtheorem*{solution}{Solution}

\surroundwithmdframed[%
    linecolor=black!20!white,%
    hidealllines=false,%
    innertopmargin=5,%
    innerbottommargin=10,%
    skipabove=0,%
    skipbelow=0,%
]{example}

\numberwithin{equation}{module}

\title{
    \Large\textsc{MA2201: Analysis II} \\
    % \vspace{10pt}
    \Huge \textbf{Differentiation} \\
    \vspace{5pt}
    \Large{Spring 2021}
}
\author{
    \large Satvik Saha%
    % \thanks{Email: \tt ss19ms154@iiserkol.ac.in}
    \\\textsc{\small 19MS154}
}
\date{\normalsize
    \textit{Indian Institute of Science Education and Research, Kolkata, \\
    Mohanpur, West Bengal, 741246, India.} \\
    % \vspace{10pt}
    % \today
}

\begin{document}
    \maketitle

    The origins of differential calculus lie in our attempts to approximate various
    functions using linear ones. Suppose that we have been given a curve described
    by the function $f$, and we want to \textit{locally} approximate the function
    around a point $x$ using a straight line. In other words, for a small shift $h$,
    we want to write \[
        f(x + h) \approx f(x) + kh.
    \] Here, $k$ is the slope of the straight line. In order to obtain $k$, we can
    rearrange the above to get \[
        k \approx \frac{f(x + h) - f(x)}{h}.
    \] As we pick smaller and smaller neighbourhoods of $x$, we want our
    approximation to get better and better. Thus, if such an approximation is
    possible, then the value of $k$ must stabilize. This means that the limit \[
        k = \lim_{h \to 0} \frac{f(x + h) - f(x)}{h}
    \] must exist. Note that this immediately forces the continuity of $f$, since \[
        \lim_{h \to 0} f(x + h) - f(x) = \lim_{h \to 0} h \cdot \lim_{h \to 0}
        \frac{f(x + h) - f(x)}{h} = 0k = 0,
    \] whereby $\lim_{x \to a} f(x) = f(a)$. Splitting the limit is justified
    because the individual limits exist.
    If such a limit $k$ exists, we call it the derivative of $f$ at $x$, denoted 
    $f'(x)$.
    % If the derivative of $f$ exists for all $x$ in some interval $(a, b)$, then we
    % say that $f$ is differentiable on $(a, b)$, and $f'\colon (a, b) \to \R$ is
    % called the derivative of $f$ over $(a, b)$.
    We are now able to write \[
        f(x + h) \approx f(x) + f'(x)h.
    \] 

    \begin{definition}[Derivative]
        The derivative of a function $f\colon [a, b] \to \R$ at a point $x \in [a,
        b]$ is defined as \[
            f'(x) = \lim_{h \to 0} \frac{f(x + h) - f(x)}{h},
        \] if such a limit exists. Note that we only demand a one-sided limit if $x$
        is an endpoint.
        If the derivative of $f$ exists at every point in $[a, b]$, we say that $f$
        is differentiable on $[a, b]$.
    \end{definition}
    \begin{example}
        Consider the map $x \mapsto x^n$, where $n \in \N$. Using the binomial
        theorem, we can write \[
            (x + h)^n = x^n + nx^{n - 1}h + \dots + h^n,
        \] which means that \[
            \ddx{}x^n = \lim_{h \to 0} \frac{1}{h}\left[(x + h)^n - x^n\right] =
            \lim_{h \to 0}\left[ nx^{n - 1} + \binom{n}{2}x^{n - 2}h + \dots + h^{n
            - 1}\right] = nx^{n - 1}.
        \] 
    \end{example}
    Note that the process of differentiation we described can be generalised to
    multivariable functions. The idea is to locally approximate a function with an
    affine function. \\

    \begin{theorem}
        If $f\colon (a, b) \to \R$ is differentiable on $(a, b)$, then it is also
        continuous on $(a, b)$.
    \end{theorem}
    
    \begin{theorem}
        Let $f\colon I\to \R$ be a continuous function. Then, \begin{enumerate}
            \itemsep0
            \item $f$ maps compact sets to compact sets.
            \item $f$ maps connected sets to connected sets.
        \end{enumerate}
    \end{theorem}
    \begin{corollary}
        A continuous function $f\colon I \to \R$ maps intervals to intervals.
    \end{corollary}
    \begin{corollary}
        A continuous function $f\colon [a, b] \to \R$ attains its minimum and
        maximum on $[a, b]$.
    \end{corollary}

    \begin{definition}
        Given $f \colon (a, b) \to \R$, a point $c \in (a, b)$ is said to be a point
        of local maximum if there exists a neighbourhood $I_c$ of $c$ such that \[
            f(c) > f(x),
        \] for all $x \in I_c\setminus\{c\}$.
        There is an analogous definition for a local minimum.
    \end{definition}
    \begin{theorem}
        If $f\colon (a, b) \to \R$ is differentiable and $c \in (a, b)$ is a point
        of local minimum or maximum, then $f'(c) = 0$.
        \begin{remark}
            The converse is not true. Note that the derivative of $x \mapsto x^3$
            vanishes at $x = 0$, but that is not a local minimum or maximum.
        \end{remark}
    \end{theorem}
    \begin{proof}
        Let $c$ be a local minimum or maximum of $f$, but suppose that $f'(c) \neq 0$.
        Define the function \[
            g\colon (a, b) \to \R, \qquad g(x) = \begin{cases}
                (f(x) - f(c))/(x - c), &\text{ if } x \neq c \\                
                f'(c), &\text{ if } x = c
            \end{cases}
        \] We note that $g$ is continuous. Also, $f'(c) = g(c) \neq 0$.
        If $g(c) > 0$, there exists a neighbourhood $I_\delta = (c - \delta, c +
        \delta)$ such that for all $x \in I_\delta$, $g(x) > 0$, from the continuity
        of $g$. This means that on $I_c$, \[
            \frac{f(x) - f(c)}{x - c} > 0,
        \] which gives $f(x) > f(c)$ on $(c, c + \delta)$ and $f(x) < f(c)$ on $(c -
        \delta, c)$. This means that $c$ cannot be a local minimum, nor a local
        maximum. There is an analogous case assuming $g(c) < 0$, which leads to the
        same contradiction. Thus, we must have $f'(c) = g(c) = 0$.
    \end{proof}

    \begin{theorem}
        If $f\colon (a, b)\to \R$ is twice differentiable, and $c \in (a, b)$ is
        such that $f'(c) = 0$ and $f''(c) < 0$, then $c$ is a point of local
        maximum. If $f'(c) = 0$ and $f''(c) > 0$, then $c$ is a point of local
        minimum.
    \end{theorem}

    \begin{theorem}[Rolle's Theorem]
        Let $f\colon [a, b] \to \R$ be continuous, and differentiable on $(a, b)$,
        with $f(a) = f(b)$. Then, there exists $c \in (a, b)$ such that $f'(c) = 0$.
    \end{theorem}
    \begin{proof}
        % Without loss of generality, set $f(a) = f(b) = 0$. This can be done because
        % a function defined as $f(x) - f(a)$ satisfies all the requirements.
        Set $f(a) = f(b) = \kappa$.
        From the continuity of $f$, note that the image of the closed interval $[a,
        b]$ is another closed interval $[\alpha, \beta]$. This means that $\alpha
        \leq \kappa \leq \beta$. Note that if $\alpha = \beta = \kappa$, then the
        function $f$ is identically equal to the constant $\kappa$, hence $f'(x) =
        0$ everywhere on $[a, b]$. By the continuity of $f$, it must attain its
        maximum and minimum on $[a, b]$. If $\beta > \kappa$, then the maximum is al
        least $\beta$ and is hence not attained at the endpoints, which means that
        the point of maximum lies in $(a, b)$. If $\alpha < \kappa$, then the same
        argument shows that $f$ attains a minimum in $(a, b)$. Thus, in either case,
        we have found $c \in (a, b)$ which is either a maximum or minimum of $f$,
        i.e.\ $f'(c) = 0$.
    \end{proof}

    \begin{theorem}[Mean Value Theorem]
        Let $f\colon [a, b] \to \R$ be continuous, and differentiable on $(a, b)$.
        Then, there exists $c \in (a, b)$ such that \[
            f(b) - f(a) = f'(c)\, (b - a).
        \] 
    \end{theorem}
    \begin{proof}
        Apply Rolle's Theorem on the function defined as \[
            g\colon [a, b] \to \R, \qquad
            g(x) = f(x) - f(a) - \frac{f(b) - f(a)}{b - a}\cdot(x - a).
        \] Note that $g$ is continuous on $[a, b]$, differentiable on $(a, b)$, and
        $g(a) = g(b) = 0$.
    \end{proof}

    \begin{theorem}
        Let $f\colon \R \to \R$ be differentiable, and $f'(x) > 0$ for all $x \in
        \R$. Then, $f$ is strictly increasing on $\R$.
    \end{theorem}
    \begin{proof}
        Let $x_2 > x_1$. By the mean value theorem, we pick $c \in (x_1, x_2)$
        such that \[
            f(x_2) - f(x_1) = f'(c) (x_2 - x_1) > 0. \qedhere
        \] 
    \end{proof}
    \begin{remark}
        The converse is not true. The map $x \mapsto x^3$ is strictly increasing,
        but its derivative vanishes at $0$.
    \end{remark}


    \begin{theorem}[Chain rule]
        Let $f$ and $g$ be differentiable on $\R$. Then, $f\circ g$ is also
        differentiable, with \[
            (f\circ g)' = (f' \circ g)\cdot g'.
        \] 
    \end{theorem}
    \begin{proof}
        Fix $a \in \R$.
        Define the functions \[
            \varphi\colon \R \to \R, \qquad \varphi(x) = \begin{cases}
                (g(x) - g(a))/(x - a) &\text{ if }x \neq a\\
                g'(a), &\text{ if } x = a
            \end{cases},
        \] \[
            \psi\colon \R \to \R, \qquad \psi(y) = \begin{cases}
                (f(y) - f(b))/(y - b) &\text{ if }y \neq b\\
                f'(b), &\text{ if } y = b
            \end{cases}.
        \] Note that $\varphi$ and $\psi$ are continuous. Also, when $x \neq a$, we
        have \[
            g(x) - g(a) = \varphi(x)(x - a).
        \] Set $b = g(a)$, and write \[
            f(g(x)) - f(g(a)) = \psi(g(x))(g(x) - g(a)) = \psi(g(x))\,\varphi(x)(x -
            a).
        \] Setting $h = f\circ g$, we have \[
            \frac{h(x) - h(a)}{x - a} = \psi(g(x))\varphi(x).
        \] Taking limits $x \to a$, we use the continuity of $\varphi$, $\psi$ and
        $g$ to conclude that the derivative of $h$ is indeed defined at $a$, and \[
            h'(a) = \psi(g(a))\,\varphi(a) = f'(g(a))\,g'(a). \qedhere
        \] 
    \end{proof}

    \begin{theorem}[Inverse function theorem]
        Let $f$ be continuously differentiable on $\R$, with $f'(x) \neq 0$
        everywhere. Then, $f$ is invertible, with a continuously differentiable
        inverse.
    \end{theorem}
    \begin{corollary}
        Let $f$ be continuously differentiable on $\R$, with $f'(x_0) \neq 0$ for
        some $x_0 \in \R$. Then, there exists some neighbourhood of $x_0$ on which
        $f$ is invertible, with a continuously differentiable inverse.
    \end{corollary}
    
\end{document}
% vim: set tabstop=4 shiftwidth=4 softtabstop=4:
