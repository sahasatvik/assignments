# Linear Algebra I

$
\newcommand\C{\mathbb{C}}
\newcommand\R{\mathbb{R}}
\newcommand\Q{\mathbb{Q}}
\newcommand\Z{\mathbb{Z}}
\newcommand\N{\mathbb{N}}
\newcommand\ve[1]{\boldsymbol{#1}}
\newcommand\norm[1]{\left\Vert #1 \right\Vert}
\def\u{\ve{u}}
\def\v{\ve{v}}
\def\w{\ve{w}}
\def\e{\ve{e}}
\def\span{\operatorname{span}}
\def\Id{\operatorname{Id}}
\def\kernel{\operatorname{ker}}
\def\image{\operatorname{im}}
\def\L{\mathscr{L}}
\def\T{\mathscr{T}}
\def\ev{\operatorname{ev}}
\def\trace{\operatorname{trace}}
\def\diag{\operatorname{diag}}
\def\rank{\operatorname{rank}}
\def\adj{\operatorname{adj}}
$
## Eigenvectors and eigenvalues
Let $T\colon V \to V$ be a linear map. We note that if $[T]_\beta$ is a diagonal matrix for some ordered basis $\beta$ of $V$, the computation of quantities such as the trace and determinants of $T^k$ becomes simple.
If such a $\beta$ exists, then the linear map $T$ is called *diagonalizable*.

A matrix $A \in M_n(F)$ is called *diagonalizable* if $A$ is similar to a diagonal matrix.

Suppose $T$ is diagonalizable, and $[T]_\beta$ is diagonal with respect to the basis $\beta = \{\v_1, \dots, \v_n\}$. Then,
$$[T]_\beta = D(\lambda_1, \dots, \lambda_n)$$
for scalars $\lambda_i$. This means that $T(\v_j) = \lambda_j\v_j$. Such a basis $\beta$ is called an *eigenbasis*.

A non-zero vector $\v\in V$ is called an *eigenvector* if $T\v = \lambda\v$ for some scalar $\lambda$. The scalar $\lambda$ is called the *eigenvalue* of the eigenvector $\v$.

Note that all vectors in the null space of a linear map are eigenvectors, with eigenvalue zero.

> The only possible eigenvalues of a projection map are $0$ and $1$. This is because $P^2 = P$, so if $P\v = \lambda\v$ for $\v \neq 0$, then $\lambda^2\v = \lambda\v$.

The following conditions are equivalent: $\lambda$ is an eigenvalue of $T$, $T - \lambda I_V$ is not invertible, $\det(T - \lambda I_v) = 0$.

Let $T\colon V \to V$ be a linear map. If $lambda$ is an eigenvalue, its *eigenspace* $E_\lambda$ is defined as the set of all vectors having that eigenvalue.
$$ E_{\lambda_i} = \{\v\in V: T\v = \lambda_i\v\}. $$
If $T$ is diagonalizable with distinct eigenvalues $\lambda_1, \dots, \lambda_k$, then there exists a basis $\beta = \{\v_1, \dots, \v_n\}$ of eigenvectors, *i.e.* an eigenbasis. We can rearrange the $\v_j$ into $k$ groups such that the $i^\text{th}$ group of $r_i$ vectors have eigenvalue $\lambda_i$. Clearly, $r_1 + \dots + r_k = n$. Thus, the $i^\text{th}$ group of eigenvectors, say $\beta_i$, is a basis of the eigenspace $E_{\lambda_i}$. Thus, it follows that
$$ V = E_{\lambda_1} \oplus \dots \oplus E_{\lambda_k}. $$

> Note that for a projection map $P$, the eigenspaces $E_0$ and $E_1$ are precisely the kernel and image of $P$.