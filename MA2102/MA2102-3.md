# Linear Algebra I

$
\newcommand\C{\mathbb{C}}
\newcommand\R{\mathbb{R}}
\newcommand\Q{\mathbb{Q}}
\newcommand\Z{\mathbb{Z}}
\newcommand\N{\mathbb{N}}
\newcommand\ve[1]{\boldsymbol{#1}}
\newcommand\norm[1]{\left\Vert #1 \right\Vert}
\def\u{\ve{u}}
\def\v{\ve{v}}
\def\w{\ve{w}}
\def\e{\ve{e}}
\def\span{\operatorname{span}}
\def\Id{\operatorname{Id}}
\def\kernel{\operatorname{ker}}
\def\image{\operatorname{im}}
\def\L{\mathscr{L}}
\def\T{\mathscr{T}}
\def\ev{\operatorname{ev}}
$

## Change of basis
Let $U$, $V$, $W$, $X$ be finite dimensional vector spaces with ordered bases $\alpha, \beta, \gamma$ and $\delta$ respectively.

If $S\colon V \to W$ and $T\colon W \to X$, then
$$ [T\circ S]_\beta^\delta = [T]_\gamma^\delta [S]_\beta^\gamma. $$

If $R\colon U \to V$, then
$$ ([T]_\gamma^\delta [S]_\beta^\gamma) [R]_\alpha^\beta = [T]_\gamma^\delta ([S]_\beta^\gamma [R]_\alpha^\beta). $$

Let $T\colon V \to V$, and let $\beta, \gamma$ be two ordered bases of $V$. Then,
$$ [\Id]_\beta^\gamma [\Id]_\gamma^\beta = [\Id]_\gamma^\gamma = I_n. $$
Note that 
$$ [\Id]_\gamma^\beta [T]_\gamma^\gamma = [T]_\gamma^\beta,\qquad [T]_\gamma^\gamma [\Id]_\beta^\gamma = [T]_\beta^\gamma. $$
Thus,
$$ [T]_\beta = [\Id]_\gamma^\beta[T]_\gamma [\Id]_\beta^\gamma. $$

The matrix $[\Id]_\beta^\gamma$ is called the *change of basis matrix*. It expresses the basis vectors of $\beta$ in terms of $\gamma$.

Recall the linear isopmorphisms
$$ \phi_\beta\colon \R^n \to V, \quad (\lambda_1, \dots, \lambda_n) \mapsto \lambda_1\v_1 + \dots + \lambda_n\v_n, $$
where $\beta = \{\v_i\}$.
Now consider the linear map
$$ T\colon \R^n \to \R^n, \quad T = \phi_\gamma^{-1}\circ \phi_\beta. $$
We wish to compute $[T]$, with respect to the standard basis of $\R^n$. Thus, the $j^\text{th}$ column of $[T]$ is simply $T(\e_j) = \phi_\gamma^{-1}\circ \phi_\beta(\e_j) = \phi_\gamma^{-1}(\v_j)$.
If $\gamma = \{\v_1', \dots, \v_n'\}$ and the entries of $[T]$ are $a_{ij}$, then
$$ \phi_\gamma^{-1}(\v_j) = \phi_\gamma^{-1}(a_{1j}\v_1' + \dots + a_{nj}\v_n') = a_{ij}\e_1 + \dots + a_{nj}\e_n. $$
This means that $[T]$ is precisely $[\Id]_\beta^\gamma$.

#### Invertible maps
A linear map $T\colon V \to W$ is called *invertible* if there exists $S\colon W \to V$ such that $S\circ V = I_V$ and $V\circ S = I_W$.
Note that this implies that both $S$ and $T$ must be bijections.
Thus, $T$ is just a linear isomorphism, with $S = T^{-1}$.

Note that if $V$ is finite dimensional and $T\colon V \to W$ is invertible, then the dimensions of $V$ and $W$ are equal.

A matrix $A \in M_{m\times n}(\R)$ is called invertible if there exists $B \in M_{n\times m}(\R)$ such that $AB = I_m$, and $BA = I_n$.

Note that if $A$ is invertible, it must be a square matrix, *i.e.* $m = n$.
To show this, suppose that $B$ is an inverse of $A$. It can be shown that $B$ is unique.
$$ B = BI_m = BAB' = I_nB' = B'. $$
Define the linear maps
$$ L_A\colon \R^n \to \R^m, \qquad L_B\colon \R^m \to \R^n, $$
via the matrices acting on vectors. With respect to the standard bases $\beta_k$ of $\R^k$, $[L_A] = A$ and $[L_B] = B$. Moreover, $L_A\circ L_B = \Id$ and $L_B \circ L_A = \Id$. Thus, the Rank Nullity theorem guarantees that $m = n$.

Suppose $T\colon V\to W$ and $S\colon U \to V$ are invertible. Then, 

- $(T\circ S)^{-1} = S^{-1}\circ T^{-1}$.
- $(T^{-1})^{-1} = T$.

Let $V$ and $W$ be finite dimensional vector spaces with ordered bases $\beta$ and $\gamma$. If $T\colon V \to W$ is a linear map, then $T$ is invertible *iff* $[T]_\beta^\gamma$ is invertible. Moreover, $[T^{-1}]_\gamma^\beta = ([T]_\beta^\gamma)^{-1}$.

Consider $T\colon V\to V$ for finite dimensional $V$ with bases $\beta$ and $\gamma$. Then,
$$ Q [T]_\beta Q^{-1} = [T]_\gamma, $$
where $Q = [I_V]_\beta^\gamma$. Note that $[T]_\beta$ is invertible *iff* $[T]_\gamma$ is invertible.

#### Similarity
Matrices $A, B \in M_n(\R)$ are said to be similar if there exists an invertible matrix $Q \in M_n(\R)$ such that $Q A Q^{-1} = B$.
Note that similarity is an equivalence relation.

> $Q$ is not unique. If $QAQ^{-1} = B$, then it follows that $(\lambda Q)A(\lambda Q)^{-1} = B$ for non-zero $\lambda$.

