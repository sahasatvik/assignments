# Mathematical Methods II

$
\newcommand\C{\mathbb{C}}
\newcommand\R{\mathbb{R}}
\newcommand\Q{\mathbb{Q}}
\newcommand\Z{\mathbb{Z}}
\newcommand\N{\mathbb{N}}
\newcommand\ve[1]{\boldsymbol{#1}}
\newcommand\ppx[1]{\frac{\partial #1}{\partial x}}
\newcommand\ppt[1]{\frac{\partial #1}{\partial t}}
\newcommand\pp[3][]{\frac{\partial^{#1}{#2}}{\partial {#3}^{#1}}}
\newcommand\norm[1]{\left\lVert#1\right\rVert}
\newcommand\grad[1]{\ve{\nabla}#1}
\newcommand\divg[1]{\ve{\nabla}\cdot#1}
\newcommand\curl[1]{\ve{\nabla}\times#1}
\newcommand\lapl[1]{\nabla^2 #1}
\newcommand\E[1]{\langle #1\rangle}
$


## Partial Differential Equations

A partial differential equation typically involves a number of variables $x_1, \dots, x_n$, an unknown multivariable function $u(x_1, \dots, x_n)$ as well as its partial derivatives with respect to these variables.

$$ f\left(x_1, \dots, x_n; u_{x_1}, \dots, u_{x_n}; u_{x_1x_1} \dots, u_{x_1x_n}; \dots\right) = 0. $$

Here, we use the notation
$$ u_{x_i} = \pp{u}{x_i}, \quad u_{x_ix_j} = \pp{}{x_j}\left(\pp{u}{x_i}\right), \quad\dots.$$
We may also use Newton's notation specifically to denote derivatives with respect to time.
$$ \dot{u} = \ppt{u}, \quad \ddot{u} = \pp[2]{u}{t}, \quad\dots. $$

The special operator $\grad{} = \sum \partial/\partial{x_i}\ve{e^i}$ is often used to define the *gradient*, *divergence*, and *Laplacian*  of scalar and vector fields. Let $u(\ve{x})$ be a scalar field and $\ve{q}(\ve{x})$ be a vector field, and let $\{\ve{e^i}\}$ be our standard basis.
$$ \begin{align}
\grad{u} &= \sum_i \pp{u}{x_i} \ve{e^i}. \tag{Gradient} \\
\divg{\ve{q}} &= \sum_i \pp{q_i}{x_i}. \tag{Divergence} \\
\lapl{u} &= \sum_i \pp[2]{u}{x_i}. \tag{Laplacian}
\end{align} $$
Another quantity called the *curl* is only defined in $\R^3$ as follows.
$$ \curl{\ve{q}} = \sum_i \epsilon_{ijk}\pp{q_i}{x_j}\ve{e^k}. 
\tag{Curl} $$

### Wave Equation

$$ \ddot{u} = c^2 \nabla^2{u}. $$
In one dimension, this reduces to
$$ \pp[2]{u}{t} = c^2 \pp[2]{u}{x}. $$

A class of solutions is given by $u(x, t) = A\cos(\omega (t - x/c) + \phi)$.

### Heat Equation

$$ \ppt{T} = \alpha \lapl{T}. $$

We start with Fourier's Law, which states that the local heat flux density $\ve{q}$ is related to the gradient of the temperature as $\ve{q} = -\kappa \nabla T$. 
This means that the rate of flow of heat energy per unit area is proportional to the negative gradient of temperature locally, *i.e.* heat flows in the direction of *decreasing* temperature, proportional to the thermal conductivity $\kappa$ of the material, which is a simple scalar for isotropic materials.

The law of conservation of heat tells us that rate of change of internal heat per volume is given by $\nabla\cdot \ve{q} = -\rho\sigma\,(\partial{T}/\partial{t}) = 0$. This means that the rate of flow of heat away from a region is proportional to the rate of *decrease* in temperature of that region with time, *i.e.* loss of heat energy in a volume is directly proportional to the decrease in temperature via $Q = \rho\sigma V\Delta{T}$. Note that $\rho$ is the density of the material and $\sigma$ is its specific heat capacity.
Putting these together and using $\lapl{T} = \divg{\grad{T}}$ yields the result, with $\alpha = \kappa/\rho\sigma$.

In one dimension, this reduces to
$$ \ppt{T} = \alpha \pp[2]{T}{x}. $$

Note that for anisotropic materials, $\kappa$ is a second order tensor and hence doesn't commute with the divergence.
$$ \rho\sigma\ppt{T} = \divg{(\kappa\grad{T})}. $$


#### Diffusion Equation
The heat equation more generally describes the phenomenon of *diffusion*, when $\alpha$ is replaced by a scalar constant $D$ and $T$ is replaced by the density of the diffusing material $\phi$.

$$ \ppt{\phi} = D\lapl{\phi}. $$

#### Random walks
The diffusion equation can also be used to describe the phenomenon of random walks, such as Brownian motion, by setting $\phi = P(\ve{x}, t)$ to the probability of finding the walker at position $\ve{x}$ at time $t$.

Consider a random walk in one dimension, where the walker takes time $\tau$ per step of length $\ell$. The probability $p$ that the walker steps to the right is constant, so the probability $q$ that the walker steps left is simply $1 - p$. In this discrete case, we set $P_n(m)$ to be the probability of finding the walker at position $x = m\ell$ at time $t = n\tau$. Clearly, the walker can arrive at step $m$ only if it stepped rightwards from $m-1$ or leftwards from $m+1$, so
$$ P_{n + 1}(m) = pP_n(m-1) + qP_n(m+1). $$

In the special case that a leftward and rightward step are equally likely, *i.e.* $p = q = 1/2$, 
$$ P_{n+1}(m) - P_n(m) = \frac12(P_n(m+1) - P_n(m)) - \frac12 (P_n(m) - P_n(m - 1)). $$
In the limit of large $n$, we can approximate these quantities as differentials. Thus, using $\delta n = \delta t /\tau$ and $\delta m = \delta x /\ell$, we obtain
$$ \tau\ppt{P} = \frac{\ell^2}{2}\pp[2]{P}{x}. $$

With some rearrangement and setting $\ell^2/2\tau = D$, we identify this as the diffusion equation.

> **Question**: What does this PDE look like for $p \neq q$?  
> *Response*: Note that in the discrete case, the probability function $P_n$ can be shown to form a Binomial distribution $B(a, p)$. This is true because the probability of reaching position $m$ from $0$ in $n$ steps along a single path with $a$ steps to the right and $b = n - a$ steps to the left is simply $p^aq^b$. This is true of every path of this form, of which there are $n!/(a!b!)$. Also, we must have exactly $m$ more steps to the right than to the left, so $a = (n + m)/2$, $b = (n - m)/2$. Thus,
$$ P_n(m) = p_n(a) = \binom{n}{a}\,p^aq^{n-a}. $$
Note that $p_n(a)$ is simply the coefficient of $x^a$ in the binomial expansion $(px + q)^n$, so by setting $x=1$, we verify that the sum of probabilities over all $a$, ranging from $0$ to $n$ is exactly $1$.
The expectation value of the number of rightward steps is simply $\E{a} = np$, so the expected position of the walker is $\E{m} = 2\E{a} - n = n(p - q)$, so $\E{x} = n(p - q)\ell = (p-q)t\ell/\tau = vt$.
$$ v = (p-q)\frac{\ell}{\tau}, \quad\quad D = 2pq\frac{\ell^2}{\tau}. $$
Here, we set $v$ to be the *drift velocity* of the walker.
The variance of $a$ is simply $npq$, so $\E{(m - \E{m})^2} = \E{m^2} - \E{m}^2 = 4npq$. Thus, the variance of the $x$ coordinate is given by $4npq\ell^2 = 4pqt\ell^2/\tau = 2Dt$.

> A famous consequence of this this that when $p = q = 1/2$, the expected value of the squared displacement from the origin is given by $\E{m^2} = n$. Thus, the expected *distance* from the origin is simply $\sqrt{t\ell^2/\tau}$.

> By performing the limit to the continuum $(\ell, \tau) \to (0, 0)$ on the rate equation while keeping $v$ and $D$ constant, we obtain the equation of diffusion
$$ \ppt{P} = -v\ppx{P} + D\pp[2]{P}{x}. $$
One solution of this equation is the Gaussian distribution
$$ P(x, t) = \frac{1}{\sqrt{4\pi Dt}}\exp\left(\frac{-(x - vt)^2}{4Dt}\right), $$
with the initial value $P(x, 0) = \delta(x)$.  
> The above equation is also easily generalized to higher dimensions.

# 

> **Question**: In the limiting process, the ratio $\ell^2/\tau$ is held constant. This seems to imply that the speed/drift velocity of the particle $\ell/\tau$ blows up. How do we reconcile this?

# 

> **Question**: How does this general equation for random walks relate to the diffusion of particles?  
> *Response*: For a large collection of particles performing such a random walk, it is clear that the density of molecules $n(\ve{x}, t)$ is simply proportional to the probability of a molecule being at $(\ve{x}, t)$, so $n(\ve{x}, t) = n_{tot}P(\ve{x}, t)$. We define the current density of particles $\ve{j}(\ve{x}, t)$ and note that analogous to Fourier's law, particles tend to move from regions of higher density to regions of lower density. This is called Fick's law, which states
$$ \ve{j}(\ve{x}, t) = -D\, \grad{n}(\ve{r}, t). $$
The constant streaming of particles with a drift velocity $\ve{v}$ introduces an additional flux term, so 
$$ \ve{j}(\ve{x}, t) = \ve{v}n(\ve{x}, t) - D\, \grad{n}(\ve{r}, t). $$
The conservation of the number of particles is expressed by the continuity equation
$$ \ppt{}n(\ve{x}, t) + \divg{\ve{j}(\ve{x}, t)} = 0. $$
Plugging in the expression for $\ve{j}(\ve{x}, t)$ yields
$$ \ppt{}n(\ve{x}, t) = -\ve{v}\cdot\grad{n(\ve{x}, t)} \,+\, D\,\lapl{n(\ve{x}, t)}. $$

### Laplace's Equation
$$ \lapl{\phi}(\ve{x}) = 0. $$
This equation is often used to describe various physical potentials $\phi(\ve{x})$, such as gravitational or electrostatic potential in regions without matter or charge respectively.

### Poisson's Equation
$$ \lapl{\phi(\ve{x})} = f(\ve{x}). $$
This equation is often used to describe potentials in the presence of some 'source', such as gravitational or electrostatic potentials in the presence of matter or charge. Here, $f(\ve{x})$ is often called the *source density*. Note that this is a special case of the heat equation where the function $T(\ve{x})$ is independent of time.

## Solving PDE's
#### Separation of Variables
Consider the region $D = \{(x, y) \in \R^2 : 0 \leq x \leq a, 0 \leq y \}$. We model the temperature in this region $T(x, y)$ using the PDE
$$ \lapl{T} = \pp[2]{T}{x} + \pp[2]{T}{y} = 0. $$

We first look for *boundary conditions*. Let $T(x, 0) = T_0$
and $T(x, \infty) = T(0, y) = T(a, y) = 0$. These are called *Dirichlet conditions*.

> There are other sorts of boundary conditions too. For example, *Neumann conditions* specify the fluxes (derivatives) at the boundaries instead of the function values.

We assume that the function $T$ can be separated into functions of single variables, *i.e.* $T(x, y) = X(x)Y(y)$.
Thus, our PDE can be written as
$$ \frac{X''(x)}{X(x)} = - \frac{Y''(y)}{Y(y)}. $$

Since both sides are functions of separate variables, they must be constant, say $\lambda$. Thus, we have the system of ODES
$$ X''(x) = \lambda X(x), \quad\quad Y''(y)  = -\lambda Y(y). $$
Now, we use the symmetry of our boundary conditions to conclude that
$$ X(x) = A_x\sin(n\pi x/a), \quad\quad Y(y) = A_y\exp(-n\pi y/a). $$
We have implicitly chosen $\lambda < 0$, specifically $\lambda = -(n\pi/a)^2$.
Note that we have chosen $\exp(-n\pi y/a)$ to satisfy the boundary condition $T(x, y) \to 0$ as $y \to \infty$.

This alone does not solve our equation. Instead, we take a superposition of all such solutions, with $n \in \N$.
Thus,

$$ T(x, y) = \sum_{n = 1}^\infty A_n \sin(n\pi x/a)\exp(-n\pi y/a). $$

Clearly, $T(0, y) = T(a, y) = 0$. Thus, we must choose $A_n$ such that $T(x, 0) = T_0$. Note that
$$ T(x, 0) = \sum_{n=1}^{\infty} A_n\sin(n\pi x/a) = \sum_{n=-\infty}^\infty U_n\,e^{in\pi x/a}. $$
Make the substitution $\varphi = \pi x/a$.
Now, we use the identity
$$ \frac{1}{2\pi}\int_0^{2\pi} e^{in\varphi} \:d\varphi = 
\begin{cases}1, & \text{if }\, n = 0 \\
0, & \text{if }\, n \neq 0
\end{cases}
$$
Thus,
$$ U_n = \frac{1}{a}\int_0^{a} T(x, 0)\, e^{-in\pi x/a} \:dx \;=\; \frac{T_0}{in\pi}(1 - e^{-in\pi}).
$$

Thus,
$$ A_n = 2iU_{n} \;=\; \frac{2T_0}{n\pi}(1 - \cos(n\pi)). $$

This gives us our solution,
$$ T(x, y) = \sum_{n = 1}^\infty \;\frac{2T_0}{n\pi}(1 - \cos(n\pi)) \sin(n\pi x/a)\exp(-n\pi y/a). $$

> Laplace's Equation in 2D can be elegantly solved using *complex analysis*. Note that all analytic functions satisfy the Cauchy-Riemann equations, so if $f = u + iv$ is analytic, for real functions $u, v$, then $ u_x = v_y$ and $u_y = -v_x$. Thus, $u_{xx} = v_{yx} = v_{xy} = -u_{yy}$, with an analogous process for $v_{xx} = -v_{yy}$. Thus, both $u$ and $v$ satisfy Laplace's equation, and are called *harmonic functions*. Our initial problem thus reduces to finding some analytic function $f$ which satisfies the given boundary conditions.

#### Fourier Series

The Fourier series of an integrable function $f$ with period $T$ is given by

$$ f(x) = \frac{a_0}{2} \,+\, \sum_{n = 1}^\infty a_n\cos\frac{n\pi x}{T} \,+\, \sum_{n = 1}^\infty b_n\sin\frac{n\pi x}{T}, $$
where the Fourier coefficients $a_n$ and $b_n$ are given by
$$ a_n = \frac{2}{T} \int_0^T f(x) \cos\frac{n\pi x}{T} \:dx,
\quad\quad b_n = \frac{2}{T} \int_0^T f(x) \sin\frac{n\pi x}{T} \:dx.$$